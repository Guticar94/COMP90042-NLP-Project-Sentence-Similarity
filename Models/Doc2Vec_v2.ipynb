{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%pip install gensim nltk pandas\n",
        "\n",
        "Code based on https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import collections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read train claims\n",
        "with open('../data/train-claims.json', 'r') as f:\n",
        "    claims = json.load(f)\n",
        "\n",
        "# Read dev claims\n",
        "with open('../data/dev-claims.json', 'r') as f:\n",
        "    dev_claims = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lowercasing the 'claim_text' field for each claim\n",
        "for claim_id, claim_info in claims.items():\n",
        "    claim_info['claim_text'] = claim_info['claim_text'].lower()\n",
        "\n",
        "for claim_id, claim_info in dev_claims.items():\n",
        "    claim_info['claim_text'] = claim_info['claim_text'].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read evidence\n",
        "with open('../data/evidence.json', 'r') as f:\n",
        "    evidences = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "evidences = {i: str.lower(j) for i,j in evidences.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of claims for training = 1228\n",
            "Number of claims for development = 154\n",
            "Number of evidences = 1208827\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of claims for training = {0}\".format(len(claims)))\n",
        "print(\"Number of claims for development = {0}\".format(len(dev_claims)))\n",
        "print(\"Number of evidences = {0}\".format(len(evidences)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from claims\n",
        "corpus = {}\n",
        "\n",
        "for id, claim in claims.items():\n",
        "#    corpus[id] = str.strip(claim['claim_text'])  # Add claim text\n",
        "\n",
        "    for evidence in claim['evidences']:\n",
        "        text = claim['claim_text'] + \" \" + evidences[evidence]\n",
        "        corpus[id + ' - ' + evidence] = str.strip(text)\n",
        "\n",
        "#for id, evidence in evidences.items():\n",
        "#    corpus[id] = str.strip(evidence) # Add evidence text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from claims\n",
        "#corpus = {}\n",
        "#for id, claim in claims.items():\n",
        "#    corpus[id] = str.strip(claim['claim_text'])  # Add claim text\n",
        "\n",
        "#for id, evidence in evidences.items():\n",
        "#    corpus[id] = str.strip(evidence) # Add evidence text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_text(df, column):\n",
        "    df['tokens'] = df[column].apply(lambda x: [token for token in word_tokenize(x) if token.isalnum()])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the list of documents into a pandas DataFrame\n",
        "df = pd.DataFrame.from_dict(corpus, orient='index', columns=['text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-442946</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-1194317</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-12171</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126 - evidence-338219</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126 - evidence-1127398</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-502 - evidence-583187</th>\n",
              "      <td>but abnormal temperature spikes in february an...</td>\n",
              "      <td>[but, abnormal, temperature, spikes, in, febru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-971105</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-457769</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-298971</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-883158</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4122 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            text  \\\n",
              "claim-1937 - evidence-442946   not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-1194317  not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-12171    not only is there no scientific evidence that ...   \n",
              "claim-126 - evidence-338219    el niño drove record highs in global temperatu...   \n",
              "claim-126 - evidence-1127398   el niño drove record highs in global temperatu...   \n",
              "...                                                                          ...   \n",
              "claim-502 - evidence-583187    but abnormal temperature spikes in february an...   \n",
              "claim-3093 - evidence-971105   sending oscillating microwaves from an antenna...   \n",
              "claim-3093 - evidence-457769   sending oscillating microwaves from an antenna...   \n",
              "claim-3093 - evidence-298971   sending oscillating microwaves from an antenna...   \n",
              "claim-3093 - evidence-883158   sending oscillating microwaves from an antenna...   \n",
              "\n",
              "                                                                          tokens  \n",
              "claim-1937 - evidence-442946   [not, only, is, there, no, scientific, evidenc...  \n",
              "claim-1937 - evidence-1194317  [not, only, is, there, no, scientific, evidenc...  \n",
              "claim-1937 - evidence-12171    [not, only, is, there, no, scientific, evidenc...  \n",
              "claim-126 - evidence-338219    [el, niño, drove, record, highs, in, global, t...  \n",
              "claim-126 - evidence-1127398   [el, niño, drove, record, highs, in, global, t...  \n",
              "...                                                                          ...  \n",
              "claim-502 - evidence-583187    [but, abnormal, temperature, spikes, in, febru...  \n",
              "claim-3093 - evidence-971105   [sending, oscillating, microwaves, from, an, a...  \n",
              "claim-3093 - evidence-457769   [sending, oscillating, microwaves, from, an, a...  \n",
              "claim-3093 - evidence-298971   [sending, oscillating, microwaves, from, an, a...  \n",
              "claim-3093 - evidence-883158   [sending, oscillating, microwaves, from, an, a...  \n",
              "\n",
              "[4122 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = tokenize_text(df,'text')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-442946</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-1194317</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-12171</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126 - evidence-338219</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "      <td>([el, niño, drove, record, highs, in, global, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126 - evidence-1127398</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "      <td>([el, niño, drove, record, highs, in, global, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-502 - evidence-583187</th>\n",
              "      <td>but abnormal temperature spikes in february an...</td>\n",
              "      <td>[but, abnormal, temperature, spikes, in, febru...</td>\n",
              "      <td>([but, abnormal, temperature, spikes, in, febr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-971105</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "      <td>([sending, oscillating, microwaves, from, an, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-457769</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "      <td>([sending, oscillating, microwaves, from, an, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-298971</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "      <td>([sending, oscillating, microwaves, from, an, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093 - evidence-883158</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "      <td>([sending, oscillating, microwaves, from, an, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4122 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            text  \\\n",
              "claim-1937 - evidence-442946   not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-1194317  not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-12171    not only is there no scientific evidence that ...   \n",
              "claim-126 - evidence-338219    el niño drove record highs in global temperatu...   \n",
              "claim-126 - evidence-1127398   el niño drove record highs in global temperatu...   \n",
              "...                                                                          ...   \n",
              "claim-502 - evidence-583187    but abnormal temperature spikes in february an...   \n",
              "claim-3093 - evidence-971105   sending oscillating microwaves from an antenna...   \n",
              "claim-3093 - evidence-457769   sending oscillating microwaves from an antenna...   \n",
              "claim-3093 - evidence-298971   sending oscillating microwaves from an antenna...   \n",
              "claim-3093 - evidence-883158   sending oscillating microwaves from an antenna...   \n",
              "\n",
              "                                                                          tokens  \\\n",
              "claim-1937 - evidence-442946   [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937 - evidence-1194317  [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937 - evidence-12171    [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-126 - evidence-338219    [el, niño, drove, record, highs, in, global, t...   \n",
              "claim-126 - evidence-1127398   [el, niño, drove, record, highs, in, global, t...   \n",
              "...                                                                          ...   \n",
              "claim-502 - evidence-583187    [but, abnormal, temperature, spikes, in, febru...   \n",
              "claim-3093 - evidence-971105   [sending, oscillating, microwaves, from, an, a...   \n",
              "claim-3093 - evidence-457769   [sending, oscillating, microwaves, from, an, a...   \n",
              "claim-3093 - evidence-298971   [sending, oscillating, microwaves, from, an, a...   \n",
              "claim-3093 - evidence-883158   [sending, oscillating, microwaves, from, an, a...   \n",
              "\n",
              "                                                                          tagged  \n",
              "claim-1937 - evidence-442946   ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937 - evidence-1194317  ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937 - evidence-12171    ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-126 - evidence-338219    ([el, niño, drove, record, highs, in, global, ...  \n",
              "claim-126 - evidence-1127398   ([el, niño, drove, record, highs, in, global, ...  \n",
              "...                                                                          ...  \n",
              "claim-502 - evidence-583187    ([but, abnormal, temperature, spikes, in, febr...  \n",
              "claim-3093 - evidence-971105   ([sending, oscillating, microwaves, from, an, ...  \n",
              "claim-3093 - evidence-457769   ([sending, oscillating, microwaves, from, an, ...  \n",
              "claim-3093 - evidence-298971   ([sending, oscillating, microwaves, from, an, ...  \n",
              "claim-3093 - evidence-883158   ([sending, oscillating, microwaves, from, an, ...  \n",
              "\n",
              "[4122 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to be applied to each row\n",
        "def process_row(row, index):\n",
        "    return TaggedDocument(row['tokens'], tags=[index])\n",
        "\n",
        "df['tagged'] = df.apply(lambda row: process_row(row, row.name), axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'at', 'very', 'high', 'concentrations', '100', 'times', 'atmospheric', 'concentration', 'or', 'greater', 'carbon', 'dioxide', 'can', 'be', 'toxic', 'to', 'animal', 'life', 'so', 'raising', 'the', 'concentration', 'to', 'ppm', '1', 'or', 'higher', 'for', 'several', 'hours', 'will', 'eliminate', 'pests', 'such', 'as', 'whiteflies', 'and', 'spider', 'mites', 'in', 'a', 'greenhouse'], tags=['claim-1937 - evidence-442946']),\n",
              "       TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'plants', 'can', 'grow', 'as', 'much', 'as', '50', 'percent', 'faster', 'in', 'concentrations', 'of', 'ppm', 'co', '2', 'when', 'compared', 'with', 'ambient', 'conditions', 'though', 'this', 'assumes', 'no', 'change', 'in', 'climate', 'and', 'no', 'limitation', 'on', 'other', 'nutrients'], tags=['claim-1937 - evidence-1194317']),\n",
              "       TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'higher', 'carbon', 'dioxide', 'concentrations', 'will', 'favourably', 'affect', 'plant', 'growth', 'and', 'demand', 'for', 'water'], tags=['claim-1937 - evidence-12171']),\n",
              "       ...,\n",
              "       TaggedDocument(words=['sending', 'oscillating', 'microwaves', 'from', 'an', 'antenna', 'inside', 'a', 'vacuum', 'through', 'an', 'electromagnetic', 'field', 'through', 'a', 'dielectric', 'material', 'such', 'as', 'water', 'creates', 'radio', 'frequency', 'heating', 'at', 'the', 'molecular', 'level', 'an', 'example', 'is', 'absorption', 'or', 'emission', 'of', 'radio', 'waves', 'by', 'antennas', 'or', 'absorption', 'of', 'microwaves', 'by', 'water', 'or', 'other', 'molecules', 'with', 'an', 'electric', 'dipole', 'moment', 'as', 'for', 'example', 'inside', 'a', 'microwave', 'oven'], tags=['claim-3093 - evidence-457769']),\n",
              "       TaggedDocument(words=['sending', 'oscillating', 'microwaves', 'from', 'an', 'antenna', 'inside', 'a', 'vacuum', 'through', 'an', 'electromagnetic', 'field', 'through', 'a', 'dielectric', 'material', 'such', 'as', 'water', 'creates', 'radio', 'frequency', 'heating', 'at', 'the', 'molecular', 'level', 'water', 'fat', 'and', 'other', 'substances', 'in', 'the', 'food', 'absorb', 'energy', 'from', 'the', 'microwaves', 'in', 'a', 'process', 'called', 'dielectric', 'heating'], tags=['claim-3093 - evidence-298971']),\n",
              "       TaggedDocument(words=['sending', 'oscillating', 'microwaves', 'from', 'an', 'antenna', 'inside', 'a', 'vacuum', 'through', 'an', 'electromagnetic', 'field', 'through', 'a', 'dielectric', 'material', 'such', 'as', 'water', 'creates', 'radio', 'frequency', 'heating', 'at', 'the', 'molecular', 'level', 'a', 'microwave', 'oven', 'passes', 'microwave', 'radiation', 'at', 'a', 'frequency', 'near', 'ghz', '12', 'cm', 'through', 'food', 'causing', 'dielectric', 'heating', 'primarily', 'by', 'absorption', 'of', 'the', 'energy', 'in', 'water'], tags=['claim-3093 - evidence-883158'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_corpus = df.tagged.values\n",
        "train_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model\n",
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Doc2Vec(vector_size=100, min_count=2, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.build_vocab(train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"Doc2Vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model.load(\"Doc2Vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assesing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>inferred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>evidence-0</th>\n",
              "      <td>john bennet lawes, english entrepreneur and ag...</td>\n",
              "      <td>[john, bennet, lawes, english, entrepreneur, a...</td>\n",
              "      <td>[-0.14050333, -0.07346727, 0.15199955, -0.2144...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1</th>\n",
              "      <td>lindberg began his professional career at the ...</td>\n",
              "      <td>[lindberg, began, his, professional, career, a...</td>\n",
              "      <td>[0.061883505, -0.32056716, -0.28470227, -0.651...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-2</th>\n",
              "      <td>``boston (ladies of cambridge)'' by vampire we...</td>\n",
              "      <td>[boston, ladies, of, cambridge, by, vampire, w...</td>\n",
              "      <td>[-0.027510643, -0.06301287, 0.11331111, 0.0033...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-3</th>\n",
              "      <td>gerald francis goyer (born october 20, 1936) w...</td>\n",
              "      <td>[gerald, francis, goyer, born, october, 20, 19...</td>\n",
              "      <td>[0.23856257, 0.24009803, -0.12047614, 0.009722...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-4</th>\n",
              "      <td>he detected abnormalities of oxytocinergic fun...</td>\n",
              "      <td>[he, detected, abnormalities, of, oxytocinergi...</td>\n",
              "      <td>[-0.036221355, -0.044179935, 0.06933342, -0.09...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208822</th>\n",
              "      <td>also on the property is a contributing garage ...</td>\n",
              "      <td>[also, on, the, property, is, a, contributing,...</td>\n",
              "      <td>[0.021422707, 0.095737614, 0.34775507, 0.12257...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208823</th>\n",
              "      <td>| class = ``fn org'' | fyrde | | | | 6110 | | ...</td>\n",
              "      <td>[class, fn, org, fyrde, 6110, volda]</td>\n",
              "      <td>[-0.105602525, 0.076353885, 0.02551154, 0.0276...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208824</th>\n",
              "      <td>dragon storm (game), a role-playing game and c...</td>\n",
              "      <td>[dragon, storm, game, a, game, and, collectibl...</td>\n",
              "      <td>[-0.1008926, 0.023352848, 0.037718453, -0.2017...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208825</th>\n",
              "      <td>it states that the zeriuani ``which is so grea...</td>\n",
              "      <td>[it, states, that, the, zeriuani, which, is, s...</td>\n",
              "      <td>[0.40652102, -0.4581477, -0.46946862, 0.645823...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208826</th>\n",
              "      <td>the storyline revolves around a giant plesiosa...</td>\n",
              "      <td>[the, storyline, revolves, around, a, giant, p...</td>\n",
              "      <td>[0.00051566656, -0.13809301, 0.22332333, -1.27...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1208827 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                               text  \\\n",
              "evidence-0        john bennet lawes, english entrepreneur and ag...   \n",
              "evidence-1        lindberg began his professional career at the ...   \n",
              "evidence-2        ``boston (ladies of cambridge)'' by vampire we...   \n",
              "evidence-3        gerald francis goyer (born october 20, 1936) w...   \n",
              "evidence-4        he detected abnormalities of oxytocinergic fun...   \n",
              "...                                                             ...   \n",
              "evidence-1208822  also on the property is a contributing garage ...   \n",
              "evidence-1208823  | class = ``fn org'' | fyrde | | | | 6110 | | ...   \n",
              "evidence-1208824  dragon storm (game), a role-playing game and c...   \n",
              "evidence-1208825  it states that the zeriuani ``which is so grea...   \n",
              "evidence-1208826  the storyline revolves around a giant plesiosa...   \n",
              "\n",
              "                                                             tokens  \\\n",
              "evidence-0        [john, bennet, lawes, english, entrepreneur, a...   \n",
              "evidence-1        [lindberg, began, his, professional, career, a...   \n",
              "evidence-2        [boston, ladies, of, cambridge, by, vampire, w...   \n",
              "evidence-3        [gerald, francis, goyer, born, october, 20, 19...   \n",
              "evidence-4        [he, detected, abnormalities, of, oxytocinergi...   \n",
              "...                                                             ...   \n",
              "evidence-1208822  [also, on, the, property, is, a, contributing,...   \n",
              "evidence-1208823               [class, fn, org, fyrde, 6110, volda]   \n",
              "evidence-1208824  [dragon, storm, game, a, game, and, collectibl...   \n",
              "evidence-1208825  [it, states, that, the, zeriuani, which, is, s...   \n",
              "evidence-1208826  [the, storyline, revolves, around, a, giant, p...   \n",
              "\n",
              "                                                           inferred  \n",
              "evidence-0        [-0.14050333, -0.07346727, 0.15199955, -0.2144...  \n",
              "evidence-1        [0.061883505, -0.32056716, -0.28470227, -0.651...  \n",
              "evidence-2        [-0.027510643, -0.06301287, 0.11331111, 0.0033...  \n",
              "evidence-3        [0.23856257, 0.24009803, -0.12047614, 0.009722...  \n",
              "evidence-4        [-0.036221355, -0.044179935, 0.06933342, -0.09...  \n",
              "...                                                             ...  \n",
              "evidence-1208822  [0.021422707, 0.095737614, 0.34775507, 0.12257...  \n",
              "evidence-1208823  [-0.105602525, 0.076353885, 0.02551154, 0.0276...  \n",
              "evidence-1208824  [-0.1008926, 0.023352848, 0.037718453, -0.2017...  \n",
              "evidence-1208825  [0.40652102, -0.4581477, -0.46946862, 0.645823...  \n",
              "evidence-1208826  [0.00051566656, -0.13809301, 0.22332333, -1.27...  \n",
              "\n",
              "[1208827 rows x 3 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evidences_df = pd.DataFrame.from_dict(evidences, orient='index', columns=['text'])\n",
        "evidences_df = tokenize_text(evidences_df,'text')\n",
        "evidences_df['inferred'] = evidences_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "evidences_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_label</th>\n",
              "      <th>evidences</th>\n",
              "      <th>tokens</th>\n",
              "      <th>inferred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-1937</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[evidence-442946, evidence-1194317, evidence-1...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>[0.17607394, 0.08539891, 0.4827279, 0.00881600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>REFUTES</td>\n",
              "      <td>[evidence-338219, evidence-1127398]</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "      <td>[0.030782836, 0.3517376, 0.13674931, 0.2072547...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2510</th>\n",
              "      <td>in 1946, pdo switched to a cool phase.</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-530063, evidence-984887]</td>\n",
              "      <td>[in, 1946, pdo, switched, to, a, cool, phase]</td>\n",
              "      <td>[-0.08643206, -0.06467303, 0.009351828, 0.0752...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2021</th>\n",
              "      <td>weather channel co-founder john coleman provid...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[evidence-1177431, evidence-782448, evidence-5...</td>\n",
              "      <td>[weather, channel, john, coleman, provided, ev...</td>\n",
              "      <td>[0.017568791, 0.014454866, -0.032761347, 0.010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2449</th>\n",
              "      <td>\"january 2008 capped a 12 month period of glob...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-1010750, evidence-91661, evidence-72...</td>\n",
              "      <td>[january, 2008, capped, a, 12, month, period, ...</td>\n",
              "      <td>[-0.014964191, 0.15340918, 0.04626587, 0.05688...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1504</th>\n",
              "      <td>climate scientists say that aspects of the cas...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-1055682, evidence-1047356, evidence-...</td>\n",
              "      <td>[climate, scientists, say, that, aspects, of, ...</td>\n",
              "      <td>[-0.21888562, 0.056726113, -0.034341607, -0.06...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-243</th>\n",
              "      <td>in its 5th assessment report in 2013, the ipcc...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-916755]</td>\n",
              "      <td>[in, its, 5th, assessment, report, in, 2013, t...</td>\n",
              "      <td>[-0.26896146, -0.03710625, -0.008333473, 0.418...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2302</th>\n",
              "      <td>since the mid 1970s, global temperatures have ...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-403673, evidence-889933, evidence-11...</td>\n",
              "      <td>[since, the, mid, 1970s, global, temperatures,...</td>\n",
              "      <td>[-0.30831116, 0.1582826, -0.27701002, 0.080839...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-502</th>\n",
              "      <td>but abnormal temperature spikes in february an...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-97375, evidence-562427, evidence-521...</td>\n",
              "      <td>[but, abnormal, temperature, spikes, in, febru...</td>\n",
              "      <td>[-0.29489544, 0.26832366, -0.5699372, 0.055965...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-971105, evidence-457769, evidence-29...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "      <td>[-0.04482069, 0.36264402, 0.00033110566, -0.13...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1228 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   claim_text  \\\n",
              "claim-1937  not only is there no scientific evidence that ...   \n",
              "claim-126   el niño drove record highs in global temperatu...   \n",
              "claim-2510             in 1946, pdo switched to a cool phase.   \n",
              "claim-2021  weather channel co-founder john coleman provid...   \n",
              "claim-2449  \"january 2008 capped a 12 month period of glob...   \n",
              "...                                                       ...   \n",
              "claim-1504  climate scientists say that aspects of the cas...   \n",
              "claim-243   in its 5th assessment report in 2013, the ipcc...   \n",
              "claim-2302  since the mid 1970s, global temperatures have ...   \n",
              "claim-502   but abnormal temperature spikes in february an...   \n",
              "claim-3093  sending oscillating microwaves from an antenna...   \n",
              "\n",
              "                claim_label  \\\n",
              "claim-1937         DISPUTED   \n",
              "claim-126           REFUTES   \n",
              "claim-2510         SUPPORTS   \n",
              "claim-2021         DISPUTED   \n",
              "claim-2449  NOT_ENOUGH_INFO   \n",
              "...                     ...   \n",
              "claim-1504         SUPPORTS   \n",
              "claim-243          SUPPORTS   \n",
              "claim-2302  NOT_ENOUGH_INFO   \n",
              "claim-502   NOT_ENOUGH_INFO   \n",
              "claim-3093         SUPPORTS   \n",
              "\n",
              "                                                    evidences  \\\n",
              "claim-1937  [evidence-442946, evidence-1194317, evidence-1...   \n",
              "claim-126                 [evidence-338219, evidence-1127398]   \n",
              "claim-2510                 [evidence-530063, evidence-984887]   \n",
              "claim-2021  [evidence-1177431, evidence-782448, evidence-5...   \n",
              "claim-2449  [evidence-1010750, evidence-91661, evidence-72...   \n",
              "...                                                       ...   \n",
              "claim-1504  [evidence-1055682, evidence-1047356, evidence-...   \n",
              "claim-243                                   [evidence-916755]   \n",
              "claim-2302  [evidence-403673, evidence-889933, evidence-11...   \n",
              "claim-502   [evidence-97375, evidence-562427, evidence-521...   \n",
              "claim-3093  [evidence-971105, evidence-457769, evidence-29...   \n",
              "\n",
              "                                                       tokens  \\\n",
              "claim-1937  [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-126   [el, niño, drove, record, highs, in, global, t...   \n",
              "claim-2510      [in, 1946, pdo, switched, to, a, cool, phase]   \n",
              "claim-2021  [weather, channel, john, coleman, provided, ev...   \n",
              "claim-2449  [january, 2008, capped, a, 12, month, period, ...   \n",
              "...                                                       ...   \n",
              "claim-1504  [climate, scientists, say, that, aspects, of, ...   \n",
              "claim-243   [in, its, 5th, assessment, report, in, 2013, t...   \n",
              "claim-2302  [since, the, mid, 1970s, global, temperatures,...   \n",
              "claim-502   [but, abnormal, temperature, spikes, in, febru...   \n",
              "claim-3093  [sending, oscillating, microwaves, from, an, a...   \n",
              "\n",
              "                                                     inferred  \n",
              "claim-1937  [0.17607394, 0.08539891, 0.4827279, 0.00881600...  \n",
              "claim-126   [0.030782836, 0.3517376, 0.13674931, 0.2072547...  \n",
              "claim-2510  [-0.08643206, -0.06467303, 0.009351828, 0.0752...  \n",
              "claim-2021  [0.017568791, 0.014454866, -0.032761347, 0.010...  \n",
              "claim-2449  [-0.014964191, 0.15340918, 0.04626587, 0.05688...  \n",
              "...                                                       ...  \n",
              "claim-1504  [-0.21888562, 0.056726113, -0.034341607, -0.06...  \n",
              "claim-243   [-0.26896146, -0.03710625, -0.008333473, 0.418...  \n",
              "claim-2302  [-0.30831116, 0.1582826, -0.27701002, 0.080839...  \n",
              "claim-502   [-0.29489544, 0.26832366, -0.5699372, 0.055965...  \n",
              "claim-3093  [-0.04482069, 0.36264402, 0.00033110566, -0.13...  \n",
              "\n",
              "[1228 rows x 5 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "claims_df = pd.DataFrame.from_dict(claims, orient='index')\n",
        "claims_df = tokenize_text(claims_df,'claim_text')\n",
        "claims_df['inferred'] = claims_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "claims_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_distance(vector1, vector2):\n",
        "    similarity = Doc2Vec.similarity_unseen_docs(model, vector1, vector2)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index2, row2 \u001b[38;5;129;01min\u001b[39;00m evidences_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      6\u001b[0m     vector2 \u001b[38;5;241m=\u001b[39m row2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     sim \u001b[38;5;241m=\u001b[39m \u001b[43mget_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m      9\u001b[0m         distances[index]\u001b[38;5;241m.\u001b[39mappend((index,sim))\n",
            "Cell \u001b[1;32mIn[24], line 2\u001b[0m, in \u001b[0;36mget_distance\u001b[1;34m(vector1, vector2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_distance\u001b[39m(vector1, vector2):\n\u001b[1;32m----> 2\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mDoc2Vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_unseen_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similarity\n",
            "File \u001b[1;32md:\\Apps\\anaconda3\\envs\\comp90042Project\\lib\\site-packages\\gensim\\models\\doc2vec.py:1088\u001b[0m, in \u001b[0;36mDoc2Vec.similarity_unseen_docs\u001b[1;34m(self, doc_words1, doc_words2, alpha, min_alpha, epochs)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between two post-bulk out of training documents.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \n\u001b[0;32m   1066\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \n\u001b[0;32m   1086\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer_vector(doc_words\u001b[38;5;241m=\u001b[39mdoc_words1, alpha\u001b[38;5;241m=\u001b[39malpha, min_alpha\u001b[38;5;241m=\u001b[39mmin_alpha, epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[1;32m-> 1088\u001b[0m d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc_words2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(matutils\u001b[38;5;241m.\u001b[39munitvec(d1), matutils\u001b[38;5;241m.\u001b[39munitvec(d2))\n",
            "File \u001b[1;32md:\\Apps\\anaconda3\\envs\\comp90042Project\\lib\\site-packages\\gensim\\models\\doc2vec.py:651\u001b[0m, in \u001b[0;36mDoc2Vec.infer_vector\u001b[1;34m(self, doc_words, alpha, min_alpha, epochs)\u001b[0m\n\u001b[0;32m    646\u001b[0m         train_document_dm_concat(\n\u001b[0;32m    647\u001b[0m             \u001b[38;5;28mself\u001b[39m, doc_words, doctag_indexes, alpha, work, neu1,\n\u001b[0;32m    648\u001b[0m             learn_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, learn_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, doctag_vectors\u001b[38;5;241m=\u001b[39mdoctag_vectors, doctags_lockf\u001b[38;5;241m=\u001b[39mdoctags_lockf\n\u001b[0;32m    649\u001b[0m         )\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 651\u001b[0m         \u001b[43mtrain_document_dm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctag_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneu1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearn_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctag_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctag_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctags_lockf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctags_lockf\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m     alpha \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m alpha_delta\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doctag_vectors[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "distances = {}\n",
        "for index, row in claims_df.iterrows():\n",
        "    vector1 = row['tokens']\n",
        "    distances[index] = []\n",
        "    for index2, row2 in evidences_df.iterrows():\n",
        "        vector2 = row2['tokens']\n",
        "        sim = get_distance(vector1, vector2)\n",
        "        if sim > 0.5:\n",
        "            distances[index].append((index,sim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_top10_rank(inferred_vector):\n",
        "    similarity_vector = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
        "    return similarity_vector[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_and_predict(sims):\n",
        "    filtered_list = [item for item in sims if not item[0].startswith('claim')]\n",
        "    prediction = [sim[0] for sim in filtered_list if sim[1] > 0.5 and sim[0]]\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_df['sims'] = train_df['inferred'].apply(lambda x: get_top10_rank(x))\n",
        "train_df['predictions'] = train_df['sims'].apply(filter_and_predict)\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_df = pd.DataFrame.from_dict(dev_claims, orient='index')\n",
        "dev_df = tokenize_text(dev_df,'claim_text')\n",
        "dev_df['inferred'] = dev_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "dev_df['sims'] = dev_df['inferred'].apply(lambda x: get_top10_rank(x))\n",
        "dev_df['predictions'] = dev_df['sims'].apply(filter_and_predict)\n",
        "dev_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the DataFrame to a Pickle file\n",
        "train_df.to_pickle('dfInferred.pkl')\n",
        "# Restore the DataFrame from the Pickle file\n",
        "#train_df = pd.read_pickle('dfInferred.pkl')\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the DataFrame to a Pickle file\n",
        "dev_df.to_pickle('devdfInferred.pkl')\n",
        "# Restore the DataFrame from the Pickle file\n",
        "#dev_df = pd.read_pickle('devdfInferred.pkl')\n",
        "dev_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df_doc2vec = train_df.copy()\n",
        "train_df_doc2vec = train_df_doc2vec.drop('evidences', axis=1)\n",
        "train_df_doc2vec = train_df_doc2vec.drop('tokens', axis=1)\n",
        "train_df_doc2vec = train_df_doc2vec.drop('inferred', axis=1)\n",
        "train_df_doc2vec = train_df_doc2vec.drop('sims', axis=1)\n",
        "train_df_doc2vec = train_df_doc2vec.rename(columns={'predictions': 'evidences'})\n",
        "train_df_doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_df_doc2vec = dev_df.copy()\n",
        "dev_df_doc2vec = dev_df_doc2vec.drop('evidences', axis=1)\n",
        "dev_df_doc2vec = dev_df_doc2vec.drop('tokens', axis=1)\n",
        "dev_df_doc2vec = dev_df_doc2vec.drop('inferred', axis=1)\n",
        "dev_df_doc2vec = dev_df_doc2vec.drop('sims', axis=1)\n",
        "dev_df_doc2vec = dev_df_doc2vec.rename(columns={'predictions': 'evidences'})\n",
        "dev_df_doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the DataFrame to a JSON file\n",
        "train_df_doc2vec.to_json('../data/train_claims_doc2vec.json', orient='index')\n",
        "dev_df_doc2vec.to_json('../data/dev_claims_doc2vec.json', orient='index')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
