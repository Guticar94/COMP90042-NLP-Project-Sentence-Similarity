{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%pip install gensim nltk pandas sklearn torch rank_bm25\n",
        "\n",
        "Code based on https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "import collections\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Garbage Collector to fix memory issues\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read train claims\n",
        "with open('../data/train-claims.json', 'r') as f:\n",
        "    claims = json.load(f)\n",
        "\n",
        "# Read dev claims\n",
        "with open('../data/dev-claims.json', 'r') as f:\n",
        "    dev_claims = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lowercasing the 'claim_text' field for each claim\n",
        "for claim_id, claim_info in claims.items():\n",
        "    claim_info['claim_text'] = claim_info['claim_text'].lower()\n",
        "\n",
        "for claim_id, claim_info in dev_claims.items():\n",
        "    claim_info['claim_text'] = claim_info['claim_text'].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read evidence\n",
        "with open('../data/evidence.json', 'r') as f:\n",
        "    evidences = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "evidences = {i: str.lower(j) for i,j in evidences.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of claims for training = 1228\n",
            "Number of claims for development = 154\n",
            "Number of evidences = 1208827\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of claims for training = {0}\".format(len(claims)))\n",
        "print(\"Number of claims for development = {0}\".format(len(dev_claims)))\n",
        "print(\"Number of evidences = {0}\".format(len(evidences)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Second approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from claims\n",
        "corpus = {}\n",
        "\n",
        "for id, claim in claims.items():\n",
        "    text2 = claim['claim_text']\n",
        "    # Create pairs claim + evidence\n",
        "    for evidence in claim['evidences']:\n",
        "        text = claim['claim_text'] + \" \" + evidences[evidence]\n",
        "        corpus[id + ' - ' + evidence] = (str.strip(text),id)\n",
        "        text2 = text2 + \" \" + evidences[evidence]\n",
        "    # Create pairs claim + all_evidence\n",
        "    corpus[id] = (str.strip(text2),claim['claim_label'])\n",
        "\n",
        "#for id, evidence in evidences.items():\n",
        "    #corpus[id] = (str.strip(evidence),id) # Add evidence text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model in claims and evidences\n",
        "# Collect all texts from claims\n",
        "#corpus = {}\n",
        "#for id, claim in claims.items():\n",
        "#    corpus[id] = str.strip(claim['claim_text'])  # Add claim text\n",
        "#for id, evidence in evidences.items():\n",
        "#    corpus[id] = str.strip(evidence) # Add evidence text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "def tokenize_text(df, column):\n",
        "    df['tokens'] = df[column].apply(lambda x: [token for token in word_tokenize(x) if token.isalnum()])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row, index):\n",
        "    return TaggedDocument(row['tokens'], tags=[row[index]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5350 entries, claim-1937 - evidence-442946 to claim-3093\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5350 non-null   object\n",
            " 1   label   5350 non-null   object\n",
            " 2   tokens  5350 non-null   object\n",
            " 3   tagged  5350 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 209.0+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-442946</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>claim-1937</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-1194317</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>claim-1937</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-12171</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>claim-1937</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126 - evidence-338219</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>claim-126</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "      <td>([el, niño, drove, record, highs, in, global, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            text  \\\n",
              "claim-1937 - evidence-442946   not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-1194317  not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-12171    not only is there no scientific evidence that ...   \n",
              "claim-1937                     not only is there no scientific evidence that ...   \n",
              "claim-126 - evidence-338219    el niño drove record highs in global temperatu...   \n",
              "\n",
              "                                    label  \\\n",
              "claim-1937 - evidence-442946   claim-1937   \n",
              "claim-1937 - evidence-1194317  claim-1937   \n",
              "claim-1937 - evidence-12171    claim-1937   \n",
              "claim-1937                       DISPUTED   \n",
              "claim-126 - evidence-338219     claim-126   \n",
              "\n",
              "                                                                          tokens  \\\n",
              "claim-1937 - evidence-442946   [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937 - evidence-1194317  [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937 - evidence-12171    [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937                     [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-126 - evidence-338219    [el, niño, drove, record, highs, in, global, t...   \n",
              "\n",
              "                                                                          tagged  \n",
              "claim-1937 - evidence-442946   ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937 - evidence-1194317  ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937 - evidence-12171    ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937                     ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-126 - evidence-338219    ([el, niño, drove, record, highs, in, global, ...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the list of documents into a pandas DataFrame\n",
        "df = pd.DataFrame.from_dict(corpus, orient='index', columns=['text','label'])\n",
        "df = tokenize_text(df,'text')\n",
        "df['tagged'] = df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'at', 'very', 'high', 'concentrations', '100', 'times', 'atmospheric', 'concentration', 'or', 'greater', 'carbon', 'dioxide', 'can', 'be', 'toxic', 'to', 'animal', 'life', 'so', 'raising', 'the', 'concentration', 'to', 'ppm', '1', 'or', 'higher', 'for', 'several', 'hours', 'will', 'eliminate', 'pests', 'such', 'as', 'whiteflies', 'and', 'spider', 'mites', 'in', 'a', 'greenhouse'], tags=['claim-1937']),\n",
              "       TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'plants', 'can', 'grow', 'as', 'much', 'as', '50', 'percent', 'faster', 'in', 'concentrations', 'of', 'ppm', 'co', '2', 'when', 'compared', 'with', 'ambient', 'conditions', 'though', 'this', 'assumes', 'no', 'change', 'in', 'climate', 'and', 'no', 'limitation', 'on', 'other', 'nutrients'], tags=['claim-1937']),\n",
              "       TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'higher', 'carbon', 'dioxide', 'concentrations', 'will', 'favourably', 'affect', 'plant', 'growth', 'and', 'demand', 'for', 'water'], tags=['claim-1937']),\n",
              "       ...,\n",
              "       TaggedDocument(words=['sending', 'oscillating', 'microwaves', 'from', 'an', 'antenna', 'inside', 'a', 'vacuum', 'through', 'an', 'electromagnetic', 'field', 'through', 'a', 'dielectric', 'material', 'such', 'as', 'water', 'creates', 'radio', 'frequency', 'heating', 'at', 'the', 'molecular', 'level', 'water', 'fat', 'and', 'other', 'substances', 'in', 'the', 'food', 'absorb', 'energy', 'from', 'the', 'microwaves', 'in', 'a', 'process', 'called', 'dielectric', 'heating'], tags=['claim-3093']),\n",
              "       TaggedDocument(words=['sending', 'oscillating', 'microwaves', 'from', 'an', 'antenna', 'inside', 'a', 'vacuum', 'through', 'an', 'electromagnetic', 'field', 'through', 'a', 'dielectric', 'material', 'such', 'as', 'water', 'creates', 'radio', 'frequency', 'heating', 'at', 'the', 'molecular', 'level', 'a', 'microwave', 'oven', 'passes', 'microwave', 'radiation', 'at', 'a', 'frequency', 'near', 'ghz', '12', 'cm', 'through', 'food', 'causing', 'dielectric', 'heating', 'primarily', 'by', 'absorption', 'of', 'the', 'energy', 'in', 'water'], tags=['claim-3093']),\n",
              "       TaggedDocument(words=['sending', 'oscillating', 'microwaves', 'from', 'an', 'antenna', 'inside', 'a', 'vacuum', 'through', 'an', 'electromagnetic', 'field', 'through', 'a', 'dielectric', 'material', 'such', 'as', 'water', 'creates', 'radio', 'frequency', 'heating', 'at', 'the', 'molecular', 'level', 'dielectric', 'heating', 'also', 'known', 'as', 'electronic', 'heating', 'radio', 'frequency', 'heating', 'and', 'heating', 'is', 'the', 'process', 'in', 'which', 'a', 'radio', 'frequency', 'rf', 'alternating', 'electric', 'field', 'or', 'radio', 'wave', 'or', 'microwave', 'electromagnetic', 'radiation', 'heats', 'a', 'dielectric', 'material', 'an', 'example', 'is', 'absorption', 'or', 'emission', 'of', 'radio', 'waves', 'by', 'antennas', 'or', 'absorption', 'of', 'microwaves', 'by', 'water', 'or', 'other', 'molecules', 'with', 'an', 'electric', 'dipole', 'moment', 'as', 'for', 'example', 'inside', 'a', 'microwave', 'oven', 'water', 'fat', 'and', 'other', 'substances', 'in', 'the', 'food', 'absorb', 'energy', 'from', 'the', 'microwaves', 'in', 'a', 'process', 'called', 'dielectric', 'heating', 'a', 'microwave', 'oven', 'passes', 'microwave', 'radiation', 'at', 'a', 'frequency', 'near', 'ghz', '12', 'cm', 'through', 'food', 'causing', 'dielectric', 'heating', 'primarily', 'by', 'absorption', 'of', 'the', 'energy', 'in', 'water'], tags=['SUPPORTS'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_corpus = df.tagged.values\n",
        "del df\n",
        "gc.collect()\n",
        "train_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "dv_corpus = {}\n",
        "\n",
        "for id, claim in dev_claims.items():\n",
        "    text2 = claim['claim_text']\n",
        "    # Create pairs claim + evidence\n",
        "    for evidence in claim['evidences']:\n",
        "        text = claim['claim_text'] + \" \" + evidences[evidence]\n",
        "        dv_corpus[id + ' - ' + evidence] = (str.strip(text),id)\n",
        "        text2 = text2 + \" \" + evidences[evidence]\n",
        "    # Create pairs claim + all_evidence\n",
        "    dv_corpus[id] = (str.strip(text2),claim['claim_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 645 entries, claim-752 - evidence-67732 to claim-1021\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    645 non-null    object\n",
            " 1   label   645 non-null    object\n",
            " 2   tokens  645 non-null    object\n",
            " 3   tagged  645 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 25.2+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-752 - evidence-67732</th>\n",
              "      <td>[south australia] has the most expensive elect...</td>\n",
              "      <td>claim-752</td>\n",
              "      <td>[south, australia, has, the, most, expensive, ...</td>\n",
              "      <td>([south, australia, has, the, most, expensive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-752 - evidence-572512</th>\n",
              "      <td>[south australia] has the most expensive elect...</td>\n",
              "      <td>claim-752</td>\n",
              "      <td>[south, australia, has, the, most, expensive, ...</td>\n",
              "      <td>([south, australia, has, the, most, expensive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-752</th>\n",
              "      <td>[south australia] has the most expensive elect...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[south, australia, has, the, most, expensive, ...</td>\n",
              "      <td>([south, australia, has, the, most, expensive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-375 - evidence-996421</th>\n",
              "      <td>when 3 per cent of total annual global emissio...</td>\n",
              "      <td>claim-375</td>\n",
              "      <td>[when, 3, per, cent, of, total, annual, global...</td>\n",
              "      <td>([when, 3, per, cent, of, total, annual, globa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-375 - evidence-1080858</th>\n",
              "      <td>when 3 per cent of total annual global emissio...</td>\n",
              "      <td>claim-375</td>\n",
              "      <td>[when, 3, per, cent, of, total, annual, global...</td>\n",
              "      <td>([when, 3, per, cent, of, total, annual, globa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                           text  \\\n",
              "claim-752 - evidence-67732    [south australia] has the most expensive elect...   \n",
              "claim-752 - evidence-572512   [south australia] has the most expensive elect...   \n",
              "claim-752                     [south australia] has the most expensive elect...   \n",
              "claim-375 - evidence-996421   when 3 per cent of total annual global emissio...   \n",
              "claim-375 - evidence-1080858  when 3 per cent of total annual global emissio...   \n",
              "\n",
              "                                  label  \\\n",
              "claim-752 - evidence-67732    claim-752   \n",
              "claim-752 - evidence-572512   claim-752   \n",
              "claim-752                      SUPPORTS   \n",
              "claim-375 - evidence-996421   claim-375   \n",
              "claim-375 - evidence-1080858  claim-375   \n",
              "\n",
              "                                                                         tokens  \\\n",
              "claim-752 - evidence-67732    [south, australia, has, the, most, expensive, ...   \n",
              "claim-752 - evidence-572512   [south, australia, has, the, most, expensive, ...   \n",
              "claim-752                     [south, australia, has, the, most, expensive, ...   \n",
              "claim-375 - evidence-996421   [when, 3, per, cent, of, total, annual, global...   \n",
              "claim-375 - evidence-1080858  [when, 3, per, cent, of, total, annual, global...   \n",
              "\n",
              "                                                                         tagged  \n",
              "claim-752 - evidence-67732    ([south, australia, has, the, most, expensive,...  \n",
              "claim-752 - evidence-572512   ([south, australia, has, the, most, expensive,...  \n",
              "claim-752                     ([south, australia, has, the, most, expensive,...  \n",
              "claim-375 - evidence-996421   ([when, 3, per, cent, of, total, annual, globa...  \n",
              "claim-375 - evidence-1080858  ([when, 3, per, cent, of, total, annual, globa...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Collect all texts from dev claims\n",
        "dev_df = pd.DataFrame.from_dict(dv_corpus, orient='index', columns=['text','label'])\n",
        "dev_df = tokenize_text(dev_df,'text')\n",
        "dev_df['tagged'] = dev_df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "dev_df.info()\n",
        "dev_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_corpus = dev_df.tagged.values\n",
        "dev_corpus[0:5]\n",
        "del dev_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model\n",
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Doc2Vec model\n",
        "model = Doc2Vec(dm=1, vector_size=50, window=5, min_count=1, workers=cores, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.build_vocab(train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    '''Callback to log information about training'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "        self.last_signal = datetime.now()\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        t = datetime.now() - self.last_signal\n",
        "        print(\"Epoch #{} - Duration: {}\".format(self.epoch, t))\n",
        "        self.epoch += 1\n",
        "        self.last_signal = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Duration: 0:00:00.458647\n",
            "Epoch #1 - Duration: 0:00:00.449724\n",
            "Epoch #2 - Duration: 0:00:00.471359\n",
            "Epoch #3 - Duration: 0:00:00.523558\n",
            "Epoch #4 - Duration: 0:00:00.485636\n",
            "Epoch #5 - Duration: 0:00:00.457135\n",
            "Epoch #6 - Duration: 0:00:00.463547\n",
            "Epoch #7 - Duration: 0:00:00.448828\n",
            "Epoch #8 - Duration: 0:00:00.464263\n",
            "Epoch #9 - Duration: 0:00:00.453799\n",
            "Epoch #10 - Duration: 0:00:00.468136\n",
            "Epoch #11 - Duration: 0:00:00.465840\n",
            "Epoch #12 - Duration: 0:00:00.580568\n",
            "Epoch #13 - Duration: 0:00:00.508398\n",
            "Epoch #14 - Duration: 0:00:00.487207\n",
            "Epoch #15 - Duration: 0:00:00.495625\n",
            "Epoch #16 - Duration: 0:00:00.494600\n",
            "Epoch #17 - Duration: 0:00:00.587471\n",
            "Epoch #18 - Duration: 0:00:00.494554\n",
            "Epoch #19 - Duration: 0:00:00.455383\n",
            "Epoch #20 - Duration: 0:00:00.484910\n",
            "Epoch #21 - Duration: 0:00:00.473382\n",
            "Epoch #22 - Duration: 0:00:00.500298\n",
            "Epoch #23 - Duration: 0:00:00.503123\n",
            "Epoch #24 - Duration: 0:00:00.536248\n",
            "Epoch #25 - Duration: 0:00:00.526463\n",
            "Epoch #26 - Duration: 0:00:00.498686\n",
            "Epoch #27 - Duration: 0:00:00.468944\n",
            "Epoch #28 - Duration: 0:00:00.493972\n",
            "Epoch #29 - Duration: 0:00:00.458697\n",
            "Epoch #30 - Duration: 0:00:00.490027\n",
            "Epoch #31 - Duration: 0:00:00.464713\n",
            "Epoch #32 - Duration: 0:00:00.484891\n",
            "Epoch #33 - Duration: 0:00:00.456745\n",
            "Epoch #34 - Duration: 0:00:00.492134\n",
            "Epoch #35 - Duration: 0:00:00.456972\n",
            "Epoch #36 - Duration: 0:00:00.477300\n",
            "Epoch #37 - Duration: 0:00:00.466497\n",
            "Epoch #38 - Duration: 0:00:00.478542\n",
            "Epoch #39 - Duration: 0:00:00.460496\n",
            "Epoch #40 - Duration: 0:00:00.464310\n",
            "Epoch #41 - Duration: 0:00:00.480757\n",
            "Epoch #42 - Duration: 0:00:00.441403\n",
            "Epoch #43 - Duration: 0:00:00.468104\n",
            "Epoch #44 - Duration: 0:00:00.462896\n",
            "Epoch #45 - Duration: 0:00:00.482375\n",
            "Epoch #46 - Duration: 0:00:00.444542\n",
            "Epoch #47 - Duration: 0:00:00.463908\n",
            "Epoch #48 - Duration: 0:00:00.483672\n",
            "Epoch #49 - Duration: 0:00:00.513708\n",
            "Epoch #50 - Duration: 0:00:00.557421\n",
            "Epoch #51 - Duration: 0:00:00.528921\n",
            "Epoch #52 - Duration: 0:00:00.512348\n",
            "Epoch #53 - Duration: 0:00:00.617607\n",
            "Epoch #54 - Duration: 0:00:00.563685\n",
            "Epoch #55 - Duration: 0:00:00.554891\n",
            "Epoch #56 - Duration: 0:00:00.520669\n",
            "Epoch #57 - Duration: 0:00:00.471102\n",
            "Epoch #58 - Duration: 0:00:00.510431\n",
            "Epoch #59 - Duration: 0:00:00.530753\n",
            "Epoch #60 - Duration: 0:00:00.496755\n",
            "Epoch #61 - Duration: 0:00:00.630078\n",
            "Epoch #62 - Duration: 0:00:00.488331\n",
            "Epoch #63 - Duration: 0:00:00.460265\n",
            "Epoch #64 - Duration: 0:00:00.486581\n",
            "Epoch #65 - Duration: 0:00:00.456434\n",
            "Epoch #66 - Duration: 0:00:00.473617\n",
            "Epoch #67 - Duration: 0:00:00.436302\n",
            "Epoch #68 - Duration: 0:00:00.451710\n",
            "Epoch #69 - Duration: 0:00:00.448704\n",
            "Epoch #70 - Duration: 0:00:00.441758\n",
            "Epoch #71 - Duration: 0:00:00.464772\n",
            "Epoch #72 - Duration: 0:00:00.440127\n",
            "Epoch #73 - Duration: 0:00:00.462223\n",
            "Epoch #74 - Duration: 0:00:00.443328\n",
            "Epoch #75 - Duration: 0:00:00.475050\n",
            "Epoch #76 - Duration: 0:00:00.447595\n",
            "Epoch #77 - Duration: 0:00:00.452793\n",
            "Epoch #78 - Duration: 0:00:00.439544\n",
            "Epoch #79 - Duration: 0:00:00.453482\n",
            "Epoch #80 - Duration: 0:00:00.454325\n",
            "Epoch #81 - Duration: 0:00:00.447000\n",
            "Epoch #82 - Duration: 0:00:00.452112\n",
            "Epoch #83 - Duration: 0:00:00.434972\n",
            "Epoch #84 - Duration: 0:00:00.476690\n",
            "Epoch #85 - Duration: 0:00:00.438825\n",
            "Epoch #86 - Duration: 0:00:00.451298\n",
            "Epoch #87 - Duration: 0:00:00.444456\n",
            "Epoch #88 - Duration: 0:00:00.442484\n",
            "Epoch #89 - Duration: 0:00:00.452823\n",
            "Epoch #90 - Duration: 0:00:00.456680\n",
            "Epoch #91 - Duration: 0:00:00.449182\n",
            "Epoch #92 - Duration: 0:00:00.442166\n",
            "Epoch #93 - Duration: 0:00:00.441091\n",
            "Epoch #94 - Duration: 0:00:00.450722\n",
            "Epoch #95 - Duration: 0:00:00.452935\n",
            "Epoch #96 - Duration: 0:00:00.436052\n",
            "Epoch #97 - Duration: 0:00:00.459210\n",
            "Epoch #98 - Duration: 0:00:00.472002\n",
            "Epoch #99 - Duration: 0:00:00.432158\n"
          ]
        }
      ],
      "source": [
        "epoch_logger = EpochLogger()\n",
        "model.train(train_corpus, total_examples=model.corpus_count,  epochs=model.epochs, callbacks=[epoch_logger])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"Doc2Vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assesing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "evidences_df = pd.DataFrame.from_dict(evidences, orient='index', columns=['text'])\n",
        "evidences_df = tokenize_text(evidences_df,'text')\n",
        "evidences_df['inferred'] = evidences_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "evidences_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evidences_df.to_pickle('evidences_df.pkl')\n",
        "#evidences_df = pd.read_pickle('evidences_df.pkl')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "claims_df = pd.DataFrame.from_dict(claims, orient='index')\n",
        "claims_df = tokenize_text(claims_df,'claim_text')\n",
        "claims_df['inferred'] = claims_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "claims_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "claims_df.to_pickle('claims_df.pkl')\n",
        "#claims_df = pd.read_pickle('claims_df.pkl')  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implement BM25 Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize BM25 model\n",
        "bm25 = BM25Okapi(evidences_df['tokens'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate BM25 scores for each claim\n",
        "def calculate_bm25_scores(query_tokens):\n",
        "    return bm25.get_scores(query_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the BM25 scores\")\n",
        "# Compute BM25 scores\n",
        "bm25_scores = claims_df['tokens'].apply(calculate_bm25_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_scores.to_pickle('bm25_scores.pkl')\n",
        "#bm25_scores = pd.read_pickle('bm25_scores.pkl')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract lists\n",
        "claim_vectors = claims_df['inferred'].to_list()\n",
        "evidence_vectors = evidences_df['inferred'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the similarities\")\n",
        "# Calculate Doc2Vec similarities\n",
        "doc2vec_similarities = cosine_similarity(claim_vectors, evidence_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('doc2vec_similarities.pkl','wb') as f: pickle.dump(doc2vec_similarities, f)\n",
        "#with open('doc2vec_similarities.pkl','rb') as f: doc2vec_similarities = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the lengths\n",
        "def normalize(scores):\n",
        "    return (scores - np.min(scores)) / (np.max(scores) - np.min(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "document_lengths = [len(doc) for doc in evidences_df['tokens']]\n",
        "normalized_lengths = normalize(document_lengths)\n",
        "p_normalized_lengths = np.array(0.2 * normalized_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_bm25_scores = [normalize(doc) for doc in bm25_scores]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_doc2vec_similarities = normalize(doc2vec_similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_bm25_scores = np.array([0.4 * doc for doc in n_bm25_scores])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_doc2vec_similarities = np.array([0.4 * doc for doc in n_doc2vec_similarities])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del document_lengths, normalized_lengths\n",
        "del bm25_scores, n_bm25_scores\n",
        "del doc2vec_similarities, n_doc2vec_similarities\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_combined_scores(bm25,similarities,lengths):\n",
        "    # Initialize an array to store the sum results\n",
        "    scores = []\n",
        "\n",
        "    # Perform the element-wise addition\n",
        "    for i in range(len(similarities)):\n",
        "        sum_result = bm25[i] + similarities[i] + lengths\n",
        "        scores.append(sum_result)\n",
        "    \n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dev claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an array to store the sum results\n",
        "combined_scores = get_combined_scores(p_bm25_scores, p_doc2vec_similarities, p_normalized_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del p_bm25_scores, p_doc2vec_similarities\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rank evidences\n",
        "ranked_index = np.argsort(combined_scores, axis=1)[:, ::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('ranked_index.pkl','wb') as f: pickle.dump(ranked_index, f)\n",
        "#with open('ranked_index.pkl','rb') as f: ranked_index = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_df = pd.DataFrame.from_dict(dev_claims, orient='index')\n",
        "dev_df = tokenize_text(dev_df,'claim_text')\n",
        "dev_df['inferred'] = dev_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "dev_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the dev BM25 scores\")\n",
        "# Compute dev BM25 scores\n",
        "dev_bm25_scores = dev_df['tokens'].apply(calculate_bm25_scores)\n",
        "n_dev_bm25_scores = [normalize(doc) for doc in dev_bm25_scores]\n",
        "p_dev_bm25_scores = np.array([0.4 * doc for doc in n_dev_bm25_scores])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_bm25_scores.to_pickle('dev_bm25_scores.pkl')\n",
        "#dev_bm25_scores = pd.read_pickle('dev_bm25_scores.pkl')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract lists\n",
        "claim_dev_vectors = dev_df['inferred'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the dev similarities\")\n",
        "# Calculate Doc2Vec similarities\n",
        "dev_doc2vec_similarities = cosine_similarity(claim_dev_vectors, evidence_vectors)\n",
        "n_dev_doc2vec_similarities = normalize(dev_doc2vec_similarities)\n",
        "p_dev_doc2vec_similarities = np.array([0.4 * doc for doc in n_dev_doc2vec_similarities])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('dev_doc2vec_similarities.pkl','wb') as f: pickle.dump(dev_doc2vec_similarities, f)\n",
        "#with open('dev_doc2vec_similarities.pkl','rb') as f: dev_doc2vec_similarities = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an array to store the sum results\n",
        "dev_combined_scores = get_combined_scores(p_dev_bm25_scores, p_dev_doc2vec_similarities, p_normalized_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del p_dev_bm25_scores, p_dev_doc2vec_similarities\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rank evidences\n",
        "dev_ranked_index = np.argsort(dev_combined_scores, axis=1)[:, ::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the list of documents into a pandas DataFrame\n",
        "df = pd.DataFrame.from_dict(corpus, orient='index', columns=['text','label'])\n",
        "df = tokenize_text(df,'text')\n",
        "df['tagged'] = df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "df = df[~df['label'].str.startswith('claim')]\n",
        "\n",
        "# Filter rows where the label does not start with 'claim'\n",
        "train_corpus = df.tagged.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "dev_df = pd.DataFrame.from_dict(dv_corpus, orient='index', columns=['text','label'])\n",
        "dev_df = tokenize_text(dev_df,'text')\n",
        "dev_df['tagged'] = dev_df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "dev_df = dev_df[~dev_df['label'].str.startswith('claim')]\n",
        "\n",
        "# Filter rows where the label does not start with 'claim'\n",
        "dev_corpus = dev_df.tagged.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label Distribution\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16,6))\n",
        "\n",
        "axs[0].set_title(\"Train\")\n",
        "axs[1].set_title(\"Validation\")\n",
        "tlabel = axs[0].hist(sorted([l for l in df['label']]))\n",
        "vlabel = axs[1].hist(sorted([l for l in dev_df['label']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vec_for_learning(model, sents):\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
        "    return targets, regressors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(n_jobs=cores, C=1e5, max_iter=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train, X_train = vec_for_learning(model, train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_dev, X_dev = vec_for_learning(model, dev_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_dev)\n",
        "print('Testing accuracy %s' % accuracy_score(y_dev, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_dev, y_pred, average='weighted')))\n",
        "report = classification_report(y_dev, y_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_pred = logreg.predict(X_train)\n",
        "print('Testing accuracy %s' % accuracy_score(y_train, y_train_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_train, y_train_pred, average='weighted')))\n",
        "report = classification_report(y_train, y_train_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = {}\n",
        "for i in range(len(claims_df)):\n",
        "    ev_list = ['evidence-'+ str(num) for num in ranked_index[i][:5] ]\n",
        "    predictions[claims_df.index[i]] = {}\n",
        "    predictions[claims_df.index[i]][\"claim_text\"] = claims_df.claim_text[i]\n",
        "    predictions[claims_df.index[i]][\"claim_label\"] = y_train_pred[i]\n",
        "    predictions[claims_df.index[i]][\"evidences\"] = ev_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the DataFrame to a JSON file\n",
        "train_df_doc2vec = pd.DataFrame.from_dict(predictions, orient='index') \n",
        "train_df_doc2vec.to_json('../data/train_claims_doc2vec.json', orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_predictions = {}\n",
        "for i in range(len(dev_df)):\n",
        "    ev_list = ['evidence-'+ str(num) for num in ranked_index[i][:5] ]\n",
        "    dev_predictions[dev_df.index[i]] = {}\n",
        "    dev_predictions[dev_df.index[i]][\"claim_text\"] = dev_df.text[i]\n",
        "    dev_predictions[dev_df.index[i]][\"claim_label\"] = y_pred[i]\n",
        "    dev_predictions[dev_df.index[i]][\"evidences\"] = ev_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the DataFrame to a JSON file\n",
        "dev_df_doc2vec = pd.DataFrame.from_dict(dev_predictions, orient='index') \n",
        "dev_df_doc2vec.to_json('../data/dev_claims_doc2vec.json', orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Information Retrieval Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load information retrieval\n",
        "ir_dev_df = pd.read_pickle('dev-trained.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "ir_dev_corpus = {}\n",
        "\n",
        "for i in range(len(ir_dev_df)):\n",
        "    text2 = ir_dev_df.iloc[i].claim_text\n",
        "    # Create pairs claim + evidence\n",
        "    for evidence in ir_dev_df.iloc[i].evidences:\n",
        "        text2 = text2 + \" \" + evidences[evidence]\n",
        "    # Create pairs claim + all_evidence\n",
        "    ir_dev_corpus[ir_dev_df.iloc[i].name] = (str.strip(text2),ir_dev_df.iloc[i].claim_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "ir_dev_df = pd.DataFrame.from_dict(ir_dev_corpus, orient='index', columns=['text','label'])\n",
        "ir_dev_df = tokenize_text(ir_dev_df,'text')\n",
        "ir_dev_df['tagged'] = ir_dev_df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "\n",
        "ir_dev_corpus = ir_dev_df.tagged.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ir_dev, X_ir_dev = vec_for_learning(model, ir_dev_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_ir_dev)\n",
        "print('Testing accuracy %s' % accuracy_score(y_ir_dev, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_ir_dev, y_pred, average='weighted')))\n",
        "report = classification_report(y_ir_dev, y_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
