{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%pip install gensim nltk pandas sklearn torch rank_bm25\n",
        "\n",
        "Code based on https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "import collections\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Garbage Collector to fix memory issues\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read train claims\n",
        "with open('../data/train-claims.json', 'r') as f:\n",
        "    claims = json.load(f)\n",
        "\n",
        "# Read dev claims\n",
        "with open('../data/dev-claims.json', 'r') as f:\n",
        "    dev_claims = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lowercasing the 'claim_text' field for each claim\n",
        "for claim_id, claim_info in claims.items():\n",
        "    claim_info['claim_text'] = claim_info['claim_text'].lower()\n",
        "\n",
        "for claim_id, claim_info in dev_claims.items():\n",
        "    claim_info['claim_text'] = claim_info['claim_text'].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read evidence\n",
        "with open('../data/evidence.json', 'r') as f:\n",
        "    evidences = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "evidences = {i: str.lower(j) for i,j in evidences.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of claims for training = 1228\n",
            "Number of claims for development = 154\n",
            "Number of evidences = 1208827\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of claims for training = {0}\".format(len(claims)))\n",
        "print(\"Number of claims for development = {0}\".format(len(dev_claims)))\n",
        "print(\"Number of evidences = {0}\".format(len(evidences)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Second approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from claims\n",
        "corpus = {}\n",
        "\n",
        "for id, claim in claims.items():\n",
        "    text2 = claim['claim_text']\n",
        "    # Create pairs claim + evidence\n",
        "    for evidence in claim['evidences']:\n",
        "        text = claim['claim_text'] + \" \" + evidences[evidence]\n",
        "        corpus[id + ' - ' + evidence] = (str.strip(text),id)\n",
        "        text2 = text2 + \" \" + evidences[evidence]\n",
        "    # Create pairs claim + all_evidence\n",
        "    corpus[id] = (str.strip(text2),claim['claim_label'])\n",
        "\n",
        "for id, evidence in evidences.items():\n",
        "    corpus[id] = (str.strip(evidence),id) # Add evidence text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model in claims and evidences\n",
        "# Collect all texts from claims\n",
        "#corpus = {}\n",
        "#for id, claim in claims.items():\n",
        "#    corpus[id] = str.strip(claim['claim_text'])  # Add claim text\n",
        "#for id, evidence in evidences.items():\n",
        "#    corpus[id] = str.strip(evidence) # Add evidence text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "def tokenize_text(df, column):\n",
        "    df['tokens'] = df[column].apply(lambda x: [token for token in word_tokenize(x) if token.isalnum()])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row, index):\n",
        "    return TaggedDocument(row['tokens'], tags=[row[index]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1214177 entries, claim-1937 - evidence-442946 to evidence-1208826\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count    Dtype \n",
            "---  ------  --------------    ----- \n",
            " 0   text    1214177 non-null  object\n",
            " 1   label   1214177 non-null  object\n",
            " 2   tokens  1214177 non-null  object\n",
            " 3   tagged  1214177 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 46.3+ MB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-442946</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>claim-1937</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-1194317</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>claim-1937</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937 - evidence-12171</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>claim-1937</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1937</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>([not, only, is, there, no, scientific, eviden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126 - evidence-338219</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>claim-126</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "      <td>([el, niño, drove, record, highs, in, global, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            text  \\\n",
              "claim-1937 - evidence-442946   not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-1194317  not only is there no scientific evidence that ...   \n",
              "claim-1937 - evidence-12171    not only is there no scientific evidence that ...   \n",
              "claim-1937                     not only is there no scientific evidence that ...   \n",
              "claim-126 - evidence-338219    el niño drove record highs in global temperatu...   \n",
              "\n",
              "                                    label  \\\n",
              "claim-1937 - evidence-442946   claim-1937   \n",
              "claim-1937 - evidence-1194317  claim-1937   \n",
              "claim-1937 - evidence-12171    claim-1937   \n",
              "claim-1937                       DISPUTED   \n",
              "claim-126 - evidence-338219     claim-126   \n",
              "\n",
              "                                                                          tokens  \\\n",
              "claim-1937 - evidence-442946   [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937 - evidence-1194317  [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937 - evidence-12171    [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-1937                     [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-126 - evidence-338219    [el, niño, drove, record, highs, in, global, t...   \n",
              "\n",
              "                                                                          tagged  \n",
              "claim-1937 - evidence-442946   ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937 - evidence-1194317  ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937 - evidence-12171    ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-1937                     ([not, only, is, there, no, scientific, eviden...  \n",
              "claim-126 - evidence-338219    ([el, niño, drove, record, highs, in, global, ...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the list of documents into a pandas DataFrame\n",
        "df = pd.DataFrame.from_dict(corpus, orient='index', columns=['text','label'])\n",
        "df = tokenize_text(df,'text')\n",
        "df['tagged'] = df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'at', 'very', 'high', 'concentrations', '100', 'times', 'atmospheric', 'concentration', 'or', 'greater', 'carbon', 'dioxide', 'can', 'be', 'toxic', 'to', 'animal', 'life', 'so', 'raising', 'the', 'concentration', 'to', 'ppm', '1', 'or', 'higher', 'for', 'several', 'hours', 'will', 'eliminate', 'pests', 'such', 'as', 'whiteflies', 'and', 'spider', 'mites', 'in', 'a', 'greenhouse'], tags=['claim-1937']),\n",
              "       TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'plants', 'can', 'grow', 'as', 'much', 'as', '50', 'percent', 'faster', 'in', 'concentrations', 'of', 'ppm', 'co', '2', 'when', 'compared', 'with', 'ambient', 'conditions', 'though', 'this', 'assumes', 'no', 'change', 'in', 'climate', 'and', 'no', 'limitation', 'on', 'other', 'nutrients'], tags=['claim-1937']),\n",
              "       TaggedDocument(words=['not', 'only', 'is', 'there', 'no', 'scientific', 'evidence', 'that', 'co2', 'is', 'a', 'pollutant', 'higher', 'co2', 'concentrations', 'actually', 'help', 'ecosystems', 'support', 'more', 'plant', 'and', 'animal', 'life', 'higher', 'carbon', 'dioxide', 'concentrations', 'will', 'favourably', 'affect', 'plant', 'growth', 'and', 'demand', 'for', 'water'], tags=['claim-1937']),\n",
              "       ...,\n",
              "       TaggedDocument(words=['dragon', 'storm', 'game', 'a', 'game', 'and', 'collectible', 'card', 'game'], tags=['evidence-1208824']),\n",
              "       TaggedDocument(words=['it', 'states', 'that', 'the', 'zeriuani', 'which', 'is', 'so', 'great', 'a', 'realm', 'that', 'from', 'it', 'as', 'their', 'tradition', 'relates', 'all', 'the', 'tribes', 'of', 'the', 'slavs', 'are', 'sprung', 'and', 'trace', 'their', 'origin', 'zeriuani', 'tantum', 'est', 'reguum', 'utex', 'eo', 'cunctae', 'gentes', 'sclavorum', 'exortae', 'sint', 'et', 'originem', 'sicut', 'affirmant', 'ducant'], tags=['evidence-1208825']),\n",
              "       TaggedDocument(words=['the', 'storyline', 'revolves', 'around', 'a', 'giant', 'plesiosaur', 'akin', 'to', 'the', 'loch', 'ness', 'monster', 'which', 'appears', 'in', 'crater', 'lake', 'in', 'northern', 'california', 'near', 'susanville', 'not', 'to', 'be', 'confused', 'with', 'the', 'much', 'more', 'famous', 'crater', 'lake', 'in', 'oregon'], tags=['evidence-1208826'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_corpus = df.tagged.values\n",
        "del df\n",
        "gc.collect()\n",
        "train_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "dv_corpus = {}\n",
        "\n",
        "for id, claim in dev_claims.items():\n",
        "    text2 = claim['claim_text']\n",
        "    # Create pairs claim + evidence\n",
        "    for evidence in claim['evidences']:\n",
        "        text = claim['claim_text'] + \" \" + evidences[evidence]\n",
        "        dv_corpus[id + ' - ' + evidence] = (str.strip(text),id)\n",
        "        text2 = text2 + \" \" + evidences[evidence]\n",
        "    # Create pairs claim + all_evidence\n",
        "    dv_corpus[id] = (str.strip(text2),claim['claim_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 645 entries, claim-752 - evidence-67732 to claim-1021\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    645 non-null    object\n",
            " 1   label   645 non-null    object\n",
            " 2   tokens  645 non-null    object\n",
            " 3   tagged  645 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 25.2+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-752 - evidence-67732</th>\n",
              "      <td>[south australia] has the most expensive elect...</td>\n",
              "      <td>claim-752</td>\n",
              "      <td>[south, australia, has, the, most, expensive, ...</td>\n",
              "      <td>([south, australia, has, the, most, expensive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-752 - evidence-572512</th>\n",
              "      <td>[south australia] has the most expensive elect...</td>\n",
              "      <td>claim-752</td>\n",
              "      <td>[south, australia, has, the, most, expensive, ...</td>\n",
              "      <td>([south, australia, has, the, most, expensive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-752</th>\n",
              "      <td>[south australia] has the most expensive elect...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[south, australia, has, the, most, expensive, ...</td>\n",
              "      <td>([south, australia, has, the, most, expensive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-375 - evidence-996421</th>\n",
              "      <td>when 3 per cent of total annual global emissio...</td>\n",
              "      <td>claim-375</td>\n",
              "      <td>[when, 3, per, cent, of, total, annual, global...</td>\n",
              "      <td>([when, 3, per, cent, of, total, annual, globa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-375 - evidence-1080858</th>\n",
              "      <td>when 3 per cent of total annual global emissio...</td>\n",
              "      <td>claim-375</td>\n",
              "      <td>[when, 3, per, cent, of, total, annual, global...</td>\n",
              "      <td>([when, 3, per, cent, of, total, annual, globa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                           text  \\\n",
              "claim-752 - evidence-67732    [south australia] has the most expensive elect...   \n",
              "claim-752 - evidence-572512   [south australia] has the most expensive elect...   \n",
              "claim-752                     [south australia] has the most expensive elect...   \n",
              "claim-375 - evidence-996421   when 3 per cent of total annual global emissio...   \n",
              "claim-375 - evidence-1080858  when 3 per cent of total annual global emissio...   \n",
              "\n",
              "                                  label  \\\n",
              "claim-752 - evidence-67732    claim-752   \n",
              "claim-752 - evidence-572512   claim-752   \n",
              "claim-752                      SUPPORTS   \n",
              "claim-375 - evidence-996421   claim-375   \n",
              "claim-375 - evidence-1080858  claim-375   \n",
              "\n",
              "                                                                         tokens  \\\n",
              "claim-752 - evidence-67732    [south, australia, has, the, most, expensive, ...   \n",
              "claim-752 - evidence-572512   [south, australia, has, the, most, expensive, ...   \n",
              "claim-752                     [south, australia, has, the, most, expensive, ...   \n",
              "claim-375 - evidence-996421   [when, 3, per, cent, of, total, annual, global...   \n",
              "claim-375 - evidence-1080858  [when, 3, per, cent, of, total, annual, global...   \n",
              "\n",
              "                                                                         tagged  \n",
              "claim-752 - evidence-67732    ([south, australia, has, the, most, expensive,...  \n",
              "claim-752 - evidence-572512   ([south, australia, has, the, most, expensive,...  \n",
              "claim-752                     ([south, australia, has, the, most, expensive,...  \n",
              "claim-375 - evidence-996421   ([when, 3, per, cent, of, total, annual, globa...  \n",
              "claim-375 - evidence-1080858  ([when, 3, per, cent, of, total, annual, globa...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Collect all texts from dev claims\n",
        "dev_df = pd.DataFrame.from_dict(dv_corpus, orient='index', columns=['text','label'])\n",
        "dev_df = tokenize_text(dev_df,'text')\n",
        "dev_df['tagged'] = dev_df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "dev_df.info()\n",
        "dev_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_corpus = dev_df.tagged.values\n",
        "dev_corpus[0:5]\n",
        "del dev_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model\n",
        "https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Doc2Vec model\n",
        "model = Doc2Vec(dm=1, vector_size=50, window=5, min_count=1, workers=cores, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.build_vocab(train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    '''Callback to log information about training'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "        self.last_signal = datetime.now()\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        t = datetime.now() - self.last_signal\n",
        "        print(\"Epoch #{} - Duration: {}\".format(self.epoch, t))\n",
        "        self.epoch += 1\n",
        "        self.last_signal = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Duration: 0:01:25.264472\n",
            "Epoch #1 - Duration: 0:01:27.318429\n",
            "Epoch #2 - Duration: 0:01:29.225444\n",
            "Epoch #3 - Duration: 0:01:31.921901\n",
            "Epoch #4 - Duration: 0:01:35.364130\n",
            "Epoch #5 - Duration: 0:01:30.431608\n",
            "Epoch #6 - Duration: 0:01:29.674299\n",
            "Epoch #7 - Duration: 0:01:29.949696\n",
            "Epoch #8 - Duration: 0:01:30.868905\n",
            "Epoch #9 - Duration: 0:01:29.813049\n",
            "Epoch #10 - Duration: 0:01:30.913694\n",
            "Epoch #11 - Duration: 0:01:29.545682\n",
            "Epoch #12 - Duration: 0:01:31.140924\n",
            "Epoch #13 - Duration: 0:01:30.205590\n",
            "Epoch #14 - Duration: 0:01:30.184621\n",
            "Epoch #15 - Duration: 0:01:30.507987\n",
            "Epoch #16 - Duration: 0:01:30.643670\n",
            "Epoch #17 - Duration: 0:01:29.865938\n",
            "Epoch #18 - Duration: 0:01:30.564549\n",
            "Epoch #19 - Duration: 0:01:29.449699\n",
            "Epoch #20 - Duration: 0:01:31.011032\n",
            "Epoch #21 - Duration: 0:01:30.001308\n",
            "Epoch #22 - Duration: 0:01:29.598903\n",
            "Epoch #23 - Duration: 0:01:30.289295\n",
            "Epoch #24 - Duration: 0:01:30.263775\n",
            "Epoch #25 - Duration: 0:01:30.889133\n",
            "Epoch #26 - Duration: 0:01:30.614006\n",
            "Epoch #27 - Duration: 0:01:30.278949\n",
            "Epoch #28 - Duration: 0:01:32.162765\n",
            "Epoch #29 - Duration: 0:01:29.234608\n",
            "Epoch #30 - Duration: 0:01:28.056122\n",
            "Epoch #31 - Duration: 0:01:28.951183\n",
            "Epoch #32 - Duration: 0:01:28.143447\n",
            "Epoch #33 - Duration: 0:01:29.004476\n",
            "Epoch #34 - Duration: 0:01:28.623905\n",
            "Epoch #35 - Duration: 0:01:28.076973\n",
            "Epoch #36 - Duration: 0:01:28.385013\n",
            "Epoch #37 - Duration: 0:01:29.907708\n",
            "Epoch #38 - Duration: 0:01:28.335750\n",
            "Epoch #39 - Duration: 0:01:28.906400\n",
            "Epoch #40 - Duration: 0:01:28.131741\n",
            "Epoch #41 - Duration: 0:01:28.061785\n",
            "Epoch #42 - Duration: 0:01:28.011088\n",
            "Epoch #43 - Duration: 0:01:30.228050\n",
            "Epoch #44 - Duration: 0:01:29.448619\n",
            "Epoch #45 - Duration: 0:01:28.940115\n",
            "Epoch #46 - Duration: 0:01:27.253397\n",
            "Epoch #47 - Duration: 0:01:29.113124\n",
            "Epoch #48 - Duration: 0:01:29.072796\n",
            "Epoch #49 - Duration: 0:01:28.593334\n",
            "Epoch #50 - Duration: 0:01:33.799444\n",
            "Epoch #51 - Duration: 0:01:28.334832\n",
            "Epoch #52 - Duration: 0:01:28.514231\n",
            "Epoch #53 - Duration: 0:01:28.372566\n",
            "Epoch #54 - Duration: 0:01:27.058326\n",
            "Epoch #55 - Duration: 0:01:28.095089\n",
            "Epoch #56 - Duration: 0:01:27.065274\n",
            "Epoch #57 - Duration: 0:01:29.876901\n",
            "Epoch #58 - Duration: 0:01:27.939295\n",
            "Epoch #59 - Duration: 0:01:28.601316\n",
            "Epoch #60 - Duration: 0:01:27.788478\n",
            "Epoch #61 - Duration: 0:01:30.695437\n",
            "Epoch #62 - Duration: 0:01:27.421309\n",
            "Epoch #63 - Duration: 0:01:27.974775\n",
            "Epoch #64 - Duration: 0:01:28.044600\n",
            "Epoch #65 - Duration: 0:01:26.991500\n",
            "Epoch #66 - Duration: 0:01:29.429217\n",
            "Epoch #67 - Duration: 0:01:27.568788\n",
            "Epoch #68 - Duration: 0:01:27.785254\n",
            "Epoch #69 - Duration: 0:01:27.923184\n",
            "Epoch #70 - Duration: 0:01:28.478138\n",
            "Epoch #71 - Duration: 0:01:31.150113\n",
            "Epoch #72 - Duration: 0:01:42.479067\n",
            "Epoch #73 - Duration: 0:01:46.641575\n",
            "Epoch #74 - Duration: 0:01:46.543655\n",
            "Epoch #75 - Duration: 0:01:41.477791\n",
            "Epoch #76 - Duration: 0:01:36.520823\n",
            "Epoch #77 - Duration: 0:01:41.056791\n",
            "Epoch #78 - Duration: 0:01:37.914624\n",
            "Epoch #79 - Duration: 0:01:36.793247\n",
            "Epoch #80 - Duration: 0:01:36.390330\n",
            "Epoch #81 - Duration: 0:01:35.076917\n",
            "Epoch #82 - Duration: 0:01:34.470236\n",
            "Epoch #83 - Duration: 0:01:30.689503\n",
            "Epoch #84 - Duration: 0:01:30.447895\n",
            "Epoch #85 - Duration: 0:01:29.406910\n",
            "Epoch #86 - Duration: 0:01:30.641828\n",
            "Epoch #87 - Duration: 0:01:29.607721\n",
            "Epoch #88 - Duration: 0:01:51.214712\n",
            "Epoch #89 - Duration: 0:01:56.005536\n",
            "Epoch #90 - Duration: 0:01:57.220859\n",
            "Epoch #91 - Duration: 0:01:52.644244\n",
            "Epoch #92 - Duration: 0:01:56.395736\n",
            "Epoch #93 - Duration: 0:01:56.221199\n",
            "Epoch #94 - Duration: 0:01:52.552634\n",
            "Epoch #95 - Duration: 0:01:56.971876\n",
            "Epoch #96 - Duration: 0:01:52.926516\n",
            "Epoch #97 - Duration: 0:01:57.503997\n",
            "Epoch #98 - Duration: 0:02:00.920977\n",
            "Epoch #99 - Duration: 0:02:01.456427\n"
          ]
        }
      ],
      "source": [
        "epoch_logger = EpochLogger()\n",
        "model.train(train_corpus, total_examples=model.corpus_count,  epochs=model.epochs, callbacks=[epoch_logger])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"Doc2Vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model.load(\"Doc2Vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assesing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>inferred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>evidence-0</th>\n",
              "      <td>john bennet lawes, english entrepreneur and ag...</td>\n",
              "      <td>[john, bennet, lawes, english, entrepreneur, a...</td>\n",
              "      <td>[-0.5866004, -0.5979908, -0.66681725, 0.566472...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1</th>\n",
              "      <td>lindberg began his professional career at the ...</td>\n",
              "      <td>[lindberg, began, his, professional, career, a...</td>\n",
              "      <td>[0.113180205, -0.7323953, -0.68200606, -0.5212...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-2</th>\n",
              "      <td>``boston (ladies of cambridge)'' by vampire we...</td>\n",
              "      <td>[boston, ladies, of, cambridge, by, vampire, w...</td>\n",
              "      <td>[0.32170302, -1.202366, -0.62181914, -0.583831...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-3</th>\n",
              "      <td>gerald francis goyer (born october 20, 1936) w...</td>\n",
              "      <td>[gerald, francis, goyer, born, october, 20, 19...</td>\n",
              "      <td>[-1.2727895, -0.04439112, -1.7628374, -0.21353...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-4</th>\n",
              "      <td>he detected abnormalities of oxytocinergic fun...</td>\n",
              "      <td>[he, detected, abnormalities, of, oxytocinergi...</td>\n",
              "      <td>[0.27375388, -1.6664252, 0.21676277, -0.375012...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208822</th>\n",
              "      <td>also on the property is a contributing garage ...</td>\n",
              "      <td>[also, on, the, property, is, a, contributing,...</td>\n",
              "      <td>[0.38326734, -0.082418896, 0.5778915, 0.757874...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208823</th>\n",
              "      <td>| class = ``fn org'' | fyrde | | | | 6110 | | ...</td>\n",
              "      <td>[class, fn, org, fyrde, 6110, volda]</td>\n",
              "      <td>[-0.4715466, -0.62071, -0.6229989, -0.10534361...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208824</th>\n",
              "      <td>dragon storm (game), a role-playing game and c...</td>\n",
              "      <td>[dragon, storm, game, a, game, and, collectibl...</td>\n",
              "      <td>[-0.052719723, -0.0347415, -1.0341836, -0.4353...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208825</th>\n",
              "      <td>it states that the zeriuani ``which is so grea...</td>\n",
              "      <td>[it, states, that, the, zeriuani, which, is, s...</td>\n",
              "      <td>[-1.4580842, -0.92808354, -0.20704237, -0.4570...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>evidence-1208826</th>\n",
              "      <td>the storyline revolves around a giant plesiosa...</td>\n",
              "      <td>[the, storyline, revolves, around, a, giant, p...</td>\n",
              "      <td>[1.2010419, 0.13606673, 1.1426569, -0.7900387,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1208827 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                               text  \\\n",
              "evidence-0        john bennet lawes, english entrepreneur and ag...   \n",
              "evidence-1        lindberg began his professional career at the ...   \n",
              "evidence-2        ``boston (ladies of cambridge)'' by vampire we...   \n",
              "evidence-3        gerald francis goyer (born october 20, 1936) w...   \n",
              "evidence-4        he detected abnormalities of oxytocinergic fun...   \n",
              "...                                                             ...   \n",
              "evidence-1208822  also on the property is a contributing garage ...   \n",
              "evidence-1208823  | class = ``fn org'' | fyrde | | | | 6110 | | ...   \n",
              "evidence-1208824  dragon storm (game), a role-playing game and c...   \n",
              "evidence-1208825  it states that the zeriuani ``which is so grea...   \n",
              "evidence-1208826  the storyline revolves around a giant plesiosa...   \n",
              "\n",
              "                                                             tokens  \\\n",
              "evidence-0        [john, bennet, lawes, english, entrepreneur, a...   \n",
              "evidence-1        [lindberg, began, his, professional, career, a...   \n",
              "evidence-2        [boston, ladies, of, cambridge, by, vampire, w...   \n",
              "evidence-3        [gerald, francis, goyer, born, october, 20, 19...   \n",
              "evidence-4        [he, detected, abnormalities, of, oxytocinergi...   \n",
              "...                                                             ...   \n",
              "evidence-1208822  [also, on, the, property, is, a, contributing,...   \n",
              "evidence-1208823               [class, fn, org, fyrde, 6110, volda]   \n",
              "evidence-1208824  [dragon, storm, game, a, game, and, collectibl...   \n",
              "evidence-1208825  [it, states, that, the, zeriuani, which, is, s...   \n",
              "evidence-1208826  [the, storyline, revolves, around, a, giant, p...   \n",
              "\n",
              "                                                           inferred  \n",
              "evidence-0        [-0.5866004, -0.5979908, -0.66681725, 0.566472...  \n",
              "evidence-1        [0.113180205, -0.7323953, -0.68200606, -0.5212...  \n",
              "evidence-2        [0.32170302, -1.202366, -0.62181914, -0.583831...  \n",
              "evidence-3        [-1.2727895, -0.04439112, -1.7628374, -0.21353...  \n",
              "evidence-4        [0.27375388, -1.6664252, 0.21676277, -0.375012...  \n",
              "...                                                             ...  \n",
              "evidence-1208822  [0.38326734, -0.082418896, 0.5778915, 0.757874...  \n",
              "evidence-1208823  [-0.4715466, -0.62071, -0.6229989, -0.10534361...  \n",
              "evidence-1208824  [-0.052719723, -0.0347415, -1.0341836, -0.4353...  \n",
              "evidence-1208825  [-1.4580842, -0.92808354, -0.20704237, -0.4570...  \n",
              "evidence-1208826  [1.2010419, 0.13606673, 1.1426569, -0.7900387,...  \n",
              "\n",
              "[1208827 rows x 3 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evidences_df = pd.DataFrame.from_dict(evidences, orient='index', columns=['text'])\n",
        "evidences_df = tokenize_text(evidences_df,'text')\n",
        "evidences_df['inferred'] = evidences_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "evidences_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "evidences_df.to_pickle('evidences_df.pkl')\n",
        "#evidences_df = pd.read_pickle('evidences_df.pkl')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_label</th>\n",
              "      <th>evidences</th>\n",
              "      <th>tokens</th>\n",
              "      <th>inferred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>claim-1937</th>\n",
              "      <td>not only is there no scientific evidence that ...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[evidence-442946, evidence-1194317, evidence-1...</td>\n",
              "      <td>[not, only, is, there, no, scientific, evidenc...</td>\n",
              "      <td>[1.382814, -1.3254179, 2.2354128, 0.6701187, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-126</th>\n",
              "      <td>el niño drove record highs in global temperatu...</td>\n",
              "      <td>REFUTES</td>\n",
              "      <td>[evidence-338219, evidence-1127398]</td>\n",
              "      <td>[el, niño, drove, record, highs, in, global, t...</td>\n",
              "      <td>[2.8369098, -0.3093397, -0.0018832907, 1.09696...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2510</th>\n",
              "      <td>in 1946, pdo switched to a cool phase.</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-530063, evidence-984887]</td>\n",
              "      <td>[in, 1946, pdo, switched, to, a, cool, phase]</td>\n",
              "      <td>[0.84987015, -0.3722064, -0.474547, -0.6948923...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2021</th>\n",
              "      <td>weather channel co-founder john coleman provid...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[evidence-1177431, evidence-782448, evidence-5...</td>\n",
              "      <td>[weather, channel, john, coleman, provided, ev...</td>\n",
              "      <td>[-0.44901243, -0.81604046, 0.46439353, 1.03122...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2449</th>\n",
              "      <td>\"january 2008 capped a 12 month period of glob...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-1010750, evidence-91661, evidence-72...</td>\n",
              "      <td>[january, 2008, capped, a, 12, month, period, ...</td>\n",
              "      <td>[-1.2736, 0.39904556, -1.0558625, 0.023528123,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-1504</th>\n",
              "      <td>climate scientists say that aspects of the cas...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-1055682, evidence-1047356, evidence-...</td>\n",
              "      <td>[climate, scientists, say, that, aspects, of, ...</td>\n",
              "      <td>[-0.558967, -1.5743817, 0.8791474, -0.35244426...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-243</th>\n",
              "      <td>in its 5th assessment report in 2013, the ipcc...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-916755]</td>\n",
              "      <td>[in, its, 5th, assessment, report, in, 2013, t...</td>\n",
              "      <td>[1.1283017, -0.38888454, 0.5755045, 0.06229574...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-2302</th>\n",
              "      <td>since the mid 1970s, global temperatures have ...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-403673, evidence-889933, evidence-11...</td>\n",
              "      <td>[since, the, mid, 1970s, global, temperatures,...</td>\n",
              "      <td>[1.0324384, -1.2101113, -0.018202715, 0.642456...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-502</th>\n",
              "      <td>but abnormal temperature spikes in february an...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-97375, evidence-562427, evidence-521...</td>\n",
              "      <td>[but, abnormal, temperature, spikes, in, febru...</td>\n",
              "      <td>[3.0434976, -1.0373944, 2.1006508, -0.4101867,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>claim-3093</th>\n",
              "      <td>sending oscillating microwaves from an antenna...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-971105, evidence-457769, evidence-29...</td>\n",
              "      <td>[sending, oscillating, microwaves, from, an, a...</td>\n",
              "      <td>[0.57838243, -1.5395635, -0.37818334, 0.116642...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1228 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   claim_text  \\\n",
              "claim-1937  not only is there no scientific evidence that ...   \n",
              "claim-126   el niño drove record highs in global temperatu...   \n",
              "claim-2510             in 1946, pdo switched to a cool phase.   \n",
              "claim-2021  weather channel co-founder john coleman provid...   \n",
              "claim-2449  \"january 2008 capped a 12 month period of glob...   \n",
              "...                                                       ...   \n",
              "claim-1504  climate scientists say that aspects of the cas...   \n",
              "claim-243   in its 5th assessment report in 2013, the ipcc...   \n",
              "claim-2302  since the mid 1970s, global temperatures have ...   \n",
              "claim-502   but abnormal temperature spikes in february an...   \n",
              "claim-3093  sending oscillating microwaves from an antenna...   \n",
              "\n",
              "                claim_label  \\\n",
              "claim-1937         DISPUTED   \n",
              "claim-126           REFUTES   \n",
              "claim-2510         SUPPORTS   \n",
              "claim-2021         DISPUTED   \n",
              "claim-2449  NOT_ENOUGH_INFO   \n",
              "...                     ...   \n",
              "claim-1504         SUPPORTS   \n",
              "claim-243          SUPPORTS   \n",
              "claim-2302  NOT_ENOUGH_INFO   \n",
              "claim-502   NOT_ENOUGH_INFO   \n",
              "claim-3093         SUPPORTS   \n",
              "\n",
              "                                                    evidences  \\\n",
              "claim-1937  [evidence-442946, evidence-1194317, evidence-1...   \n",
              "claim-126                 [evidence-338219, evidence-1127398]   \n",
              "claim-2510                 [evidence-530063, evidence-984887]   \n",
              "claim-2021  [evidence-1177431, evidence-782448, evidence-5...   \n",
              "claim-2449  [evidence-1010750, evidence-91661, evidence-72...   \n",
              "...                                                       ...   \n",
              "claim-1504  [evidence-1055682, evidence-1047356, evidence-...   \n",
              "claim-243                                   [evidence-916755]   \n",
              "claim-2302  [evidence-403673, evidence-889933, evidence-11...   \n",
              "claim-502   [evidence-97375, evidence-562427, evidence-521...   \n",
              "claim-3093  [evidence-971105, evidence-457769, evidence-29...   \n",
              "\n",
              "                                                       tokens  \\\n",
              "claim-1937  [not, only, is, there, no, scientific, evidenc...   \n",
              "claim-126   [el, niño, drove, record, highs, in, global, t...   \n",
              "claim-2510      [in, 1946, pdo, switched, to, a, cool, phase]   \n",
              "claim-2021  [weather, channel, john, coleman, provided, ev...   \n",
              "claim-2449  [january, 2008, capped, a, 12, month, period, ...   \n",
              "...                                                       ...   \n",
              "claim-1504  [climate, scientists, say, that, aspects, of, ...   \n",
              "claim-243   [in, its, 5th, assessment, report, in, 2013, t...   \n",
              "claim-2302  [since, the, mid, 1970s, global, temperatures,...   \n",
              "claim-502   [but, abnormal, temperature, spikes, in, febru...   \n",
              "claim-3093  [sending, oscillating, microwaves, from, an, a...   \n",
              "\n",
              "                                                     inferred  \n",
              "claim-1937  [1.382814, -1.3254179, 2.2354128, 0.6701187, 2...  \n",
              "claim-126   [2.8369098, -0.3093397, -0.0018832907, 1.09696...  \n",
              "claim-2510  [0.84987015, -0.3722064, -0.474547, -0.6948923...  \n",
              "claim-2021  [-0.44901243, -0.81604046, 0.46439353, 1.03122...  \n",
              "claim-2449  [-1.2736, 0.39904556, -1.0558625, 0.023528123,...  \n",
              "...                                                       ...  \n",
              "claim-1504  [-0.558967, -1.5743817, 0.8791474, -0.35244426...  \n",
              "claim-243   [1.1283017, -0.38888454, 0.5755045, 0.06229574...  \n",
              "claim-2302  [1.0324384, -1.2101113, -0.018202715, 0.642456...  \n",
              "claim-502   [3.0434976, -1.0373944, 2.1006508, -0.4101867,...  \n",
              "claim-3093  [0.57838243, -1.5395635, -0.37818334, 0.116642...  \n",
              "\n",
              "[1228 rows x 5 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "claims_df = pd.DataFrame.from_dict(claims, orient='index')\n",
        "claims_df = tokenize_text(claims_df,'claim_text')\n",
        "claims_df['inferred'] = claims_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "claims_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "claims_df.to_pickle('claims_df.pkl')\n",
        "#claims_df = pd.read_pickle('claims_df.pkl')  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implement BM25 Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize BM25 model\n",
        "bm25 = BM25Okapi(evidences_df['tokens'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate BM25 scores for each claim\n",
        "def calculate_bm25_scores(query_tokens):\n",
        "    return bm25.get_scores(query_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the BM25 scores\")\n",
        "# Compute BM25 scores\n",
        "bm25_scores = claims_df['tokens'].apply(calculate_bm25_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_scores.to_pickle('bm25_scores.pkl')\n",
        "#bm25_scores = pd.read_pickle('bm25_scores.pkl')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract lists\n",
        "claim_vectors = claims_df['inferred'].to_list()\n",
        "evidence_vectors = evidences_df['inferred'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the similarities\")\n",
        "# Calculate Doc2Vec similarities\n",
        "doc2vec_similarities = cosine_similarity(claim_vectors, evidence_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('doc2vec_similarities.pkl','wb') as f: pickle.dump(doc2vec_similarities, f)\n",
        "#with open('doc2vec_similarities.pkl','rb') as f: doc2vec_similarities = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the lengths\n",
        "def normalize(scores):\n",
        "    return (scores - np.min(scores)) / (np.max(scores) - np.min(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "document_lengths = [len(doc) for doc in evidences_df['tokens']]\n",
        "normalized_lengths = normalize(document_lengths)\n",
        "p_normalized_lengths = np.array(0.2 * normalized_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_bm25_scores = [normalize(doc) for doc in bm25_scores]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_doc2vec_similarities = normalize(doc2vec_similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_bm25_scores = np.array([0.4 * doc for doc in n_bm25_scores])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_doc2vec_similarities = np.array([0.4 * doc for doc in n_doc2vec_similarities])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del document_lengths, normalized_lengths\n",
        "del bm25_scores, n_bm25_scores\n",
        "del doc2vec_similarities, n_doc2vec_similarities\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_combined_scores(bm25,similarities,lengths):\n",
        "    # Initialize an array to store the sum results\n",
        "    scores = []\n",
        "\n",
        "    # Perform the element-wise addition\n",
        "    for i in range(len(similarities)):\n",
        "        sum_result = bm25[i] + similarities[i] + lengths\n",
        "        scores.append(sum_result)\n",
        "    \n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dev claims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an array to store the sum results\n",
        "combined_scores = get_combined_scores(p_bm25_scores, p_doc2vec_similarities, p_normalized_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del p_bm25_scores, p_doc2vec_similarities\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rank evidences\n",
        "ranked_index = np.argsort(combined_scores, axis=1)[:, ::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('ranked_index.pkl','wb') as f: pickle.dump(ranked_index, f)\n",
        "#with open('ranked_index.pkl','rb') as f: ranked_index = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_df = pd.DataFrame.from_dict(dev_claims, orient='index')\n",
        "dev_df = tokenize_text(dev_df,'claim_text')\n",
        "dev_df['inferred'] = dev_df['tokens'].apply(lambda x: model.infer_vector(x))\n",
        "dev_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the dev BM25 scores\")\n",
        "# Compute dev BM25 scores\n",
        "dev_bm25_scores = dev_df['tokens'].apply(calculate_bm25_scores)\n",
        "n_dev_bm25_scores = [normalize(doc) for doc in dev_bm25_scores]\n",
        "p_dev_bm25_scores = np.array([0.4 * doc for doc in n_dev_bm25_scores])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_bm25_scores.to_pickle('dev_bm25_scores.pkl')\n",
        "#dev_bm25_scores = pd.read_pickle('dev_bm25_scores.pkl')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract lists\n",
        "claim_dev_vectors = dev_df['inferred'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating the dev similarities\")\n",
        "# Calculate Doc2Vec similarities\n",
        "dev_doc2vec_similarities = cosine_similarity(claim_dev_vectors, evidence_vectors)\n",
        "n_dev_doc2vec_similarities = normalize(dev_doc2vec_similarities)\n",
        "p_dev_doc2vec_similarities = np.array([0.4 * doc for doc in n_dev_doc2vec_similarities])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('dev_doc2vec_similarities.pkl','wb') as f: pickle.dump(dev_doc2vec_similarities, f)\n",
        "#with open('dev_doc2vec_similarities.pkl','rb') as f: dev_doc2vec_similarities = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an array to store the sum results\n",
        "dev_combined_scores = get_combined_scores(p_dev_bm25_scores, p_dev_doc2vec_similarities, p_normalized_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del p_dev_bm25_scores, p_dev_doc2vec_similarities\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rank evidences\n",
        "dev_ranked_index = np.argsort(dev_combined_scores, axis=1)[:, ::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the list of documents into a pandas DataFrame\n",
        "df = pd.DataFrame.from_dict(corpus, orient='index', columns=['text','label'])\n",
        "df = tokenize_text(df,'text')\n",
        "df['tagged'] = df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "df = df[~df['label'].str.startswith('claim')]\n",
        "\n",
        "# Filter rows where the label does not start with 'claim'\n",
        "train_corpus = df.tagged.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "dev_df = pd.DataFrame.from_dict(dv_corpus, orient='index', columns=['text','label'])\n",
        "dev_df = tokenize_text(dev_df,'text')\n",
        "dev_df['tagged'] = dev_df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "dev_df = dev_df[~dev_df['label'].str.startswith('claim')]\n",
        "\n",
        "# Filter rows where the label does not start with 'claim'\n",
        "dev_corpus = dev_df.tagged.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label Distribution\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16,6))\n",
        "\n",
        "axs[0].set_title(\"Train\")\n",
        "axs[1].set_title(\"Validation\")\n",
        "tlabel = axs[0].hist(sorted([l for l in df['label']]))\n",
        "vlabel = axs[1].hist(sorted([l for l in dev_df['label']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vec_for_learning(model, sents):\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
        "    return targets, regressors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(n_jobs=cores, C=1e5, max_iter=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train, X_train = vec_for_learning(model, train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_dev, X_dev = vec_for_learning(model, dev_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_dev)\n",
        "print('Testing accuracy %s' % accuracy_score(y_dev, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_dev, y_pred, average='weighted')))\n",
        "report = classification_report(y_dev, y_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_pred = logreg.predict(X_train)\n",
        "print('Testing accuracy %s' % accuracy_score(y_train, y_train_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_train, y_train_pred, average='weighted')))\n",
        "report = classification_report(y_train, y_train_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = {}\n",
        "for i in range(len(claims_df)):\n",
        "    ev_list = ['evidence-'+ str(num) for num in ranked_index[i][:5] ]\n",
        "    predictions[claims_df.index[i]] = {}\n",
        "    predictions[claims_df.index[i]][\"claim_text\"] = claims_df.claim_text[i]\n",
        "    predictions[claims_df.index[i]][\"claim_label\"] = y_train_pred[i]\n",
        "    predictions[claims_df.index[i]][\"evidences\"] = ev_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the DataFrame to a JSON file\n",
        "train_df_doc2vec = pd.DataFrame.from_dict(predictions, orient='index') \n",
        "train_df_doc2vec.to_json('../data/train_claims_doc2vec.json', orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_predictions = {}\n",
        "for i in range(len(dev_df)):\n",
        "    ev_list = ['evidence-'+ str(num) for num in ranked_index[i][:5] ]\n",
        "    dev_predictions[dev_df.index[i]] = {}\n",
        "    dev_predictions[dev_df.index[i]][\"claim_text\"] = dev_df.text[i]\n",
        "    dev_predictions[dev_df.index[i]][\"claim_label\"] = y_pred[i]\n",
        "    dev_predictions[dev_df.index[i]][\"evidences\"] = ev_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the DataFrame to a JSON file\n",
        "dev_df_doc2vec = pd.DataFrame.from_dict(dev_predictions, orient='index') \n",
        "dev_df_doc2vec.to_json('../data/dev_claims_doc2vec.json', orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Information Retrieval Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load information retrieval\n",
        "ir_dev_df = pd.read_pickle('dev-trained.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "ir_dev_corpus = {}\n",
        "\n",
        "for i in range(len(ir_dev_df)):\n",
        "    text2 = ir_dev_df.iloc[i].claim_text\n",
        "    # Create pairs claim + evidence\n",
        "    for evidence in ir_dev_df.iloc[i].evidences:\n",
        "        text2 = text2 + \" \" + evidences[evidence]\n",
        "    # Create pairs claim + all_evidence\n",
        "    ir_dev_corpus[ir_dev_df.iloc[i].name] = (str.strip(text2),ir_dev_df.iloc[i].claim_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all texts from dev claims\n",
        "ir_dev_df = pd.DataFrame.from_dict(ir_dev_corpus, orient='index', columns=['text','label'])\n",
        "ir_dev_df = tokenize_text(ir_dev_df,'text')\n",
        "ir_dev_df['tagged'] = ir_dev_df.apply(lambda row: process_row(row, 'label'), axis=1)\n",
        "\n",
        "ir_dev_corpus = ir_dev_df.tagged.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_ir_dev, X_ir_dev = vec_for_learning(model, ir_dev_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_ir_dev)\n",
        "print('Testing accuracy %s' % accuracy_score(y_ir_dev, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_ir_dev, y_pred, average='weighted')))\n",
        "report = classification_report(y_ir_dev, y_pred)\n",
        "print(f\"Classification Report:\\n{report}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
