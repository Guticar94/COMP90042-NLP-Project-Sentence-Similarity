{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence similarity - TF-IDF + POS + NER\n",
    "\n",
    "This notebook holds the code for the final approach of the retreival part using a mix of TFID + NER + POS with a Cosine similarity distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stopwords = nlp.Defaults.stop_words\n",
    "# [stop_words.add(w) for w in stopwords]\n",
    "# len(stop_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing step\n",
    "The focus of this section is to transform the inputed texts to a numeric representation trying to keep as much contextual representation as posible from the texts, for so, we decided to use NER and POS tagging over the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train claims\n",
    "with open('../data/train-claims.json', 'r') as f:\n",
    "    df_train = pd.DataFrame(json.load(f)).transpose()\n",
    "\n",
    "# Read dev claims\n",
    "with open('../data/dev-claims.json', 'r') as f:\n",
    "    df_dev = pd.DataFrame(json.load(f)).transpose()\n",
    "\n",
    "# Read evidence\n",
    "with open('../data/evidence.json', 'r') as f:\n",
    "    evidence = json.load(f)\n",
    "ev_txt = [j for i,j in evidence.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER and POS texts\n",
    "def tag(text):\n",
    "    doc = nlp(text)\n",
    "    ner_tags = [entity.label_ for entity in doc.ents]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    return ner_tags, pos_tags\n",
    "\n",
    "# NER and POS texts\n",
    "def NER(text):\n",
    "    doc = nlp(text)\n",
    "    ner_tags = [entity.label_ for entity in doc.ents]\n",
    "    return ner_tags\n",
    "\n",
    "def POS(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Select columns to work on and retrieve tokenized and preprocesed vectors \n",
    "def feature_selection(feature, full=False):\n",
    "    # Set words to lower and tokenize\n",
    "    tokenized = [WordPunctTokenizer().tokenize(i.lower()) for i in feature]\n",
    "    # Drop unknown characters (This may be modified depending model performance)\n",
    "    tokenized = [' '.join([w for w in seq if re.match(r'^.*$', w)]) for seq in tokenized]\n",
    "    # Stopwords\n",
    "    tokenized = [' '.join([w for w in seq.split() if w not in stop_words]) for seq in tokenized]\n",
    "    # Lemmatization\n",
    "    tokenized = [' '.join([WordNetLemmatizer().lemmatize(w) for w in seq.split()]) for seq in tokenized]\n",
    "    if full:\n",
    "        # Extract NER and POS tags\n",
    "        ner_tags = list(map(NER,feature))\n",
    "        pos_tags = list(map(POS,feature))\n",
    "        # Concatenate texts\n",
    "        concatenated_texts = []\n",
    "        for i in range(len(tokenized)):\n",
    "            concatenated_texts.append(tokenized[i].split() + [' | '] + ner_tags[i] + [' | '] + pos_tags[i])\n",
    "        return concatenated_texts\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "ner, pos = [], []\n",
    "st = time()\n",
    "\n",
    "# Method to extract the contextual representation (NER and POS) from the evidence set\n",
    "import os\n",
    "# If the files does not exist in the ws folder extract the NER and POS files\n",
    "if not os.path.exists('../data/NER.csv'):\n",
    "    print(1)\n",
    "    ### NOTE: This function runs in over 1:20hs\n",
    "    for idx, txt in enumerate(ev_txt):\n",
    "        if idx % 10000 == 0 :\n",
    "            print(f\"Evidence No. {idx}. \\t Time: {time()-st:0.2f}\")\n",
    "        nr, ps = tag(txt)\n",
    "        ner.append(nr)\n",
    "        pos.append(ps)\n",
    "    pd.Series(ner).to_csv('../data/NER.csv')\n",
    "    pd.Series(pos).to_csv('../data/POS.csv')\n",
    "# Read the files if they exist\n",
    "else:\n",
    "    ner = pd.read_csv('../data/NER.csv', index_col=0).iloc[:,0]\n",
    "    ner = [[tag.strip(\"'\") for tag in sent.strip(\"[]\").split(\", \")] for sent in ner]\n",
    "    pos = pd.read_csv('../data/POS.csv', index_col=0).iloc[:,0]\n",
    "    pos = [[tag.strip(\"'\") for tag in sent.strip(\"[]\").split(\", \")] for sent in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dev claims and evidences\n",
    "df = df_dev.copy()\n",
    "# Claim\n",
    "claim = feature_selection(df['claim_text'], True)\n",
    "claim = [' '.join(i) for i in claim]\n",
    "# Evidence\n",
    "evidences = feature_selection(ev_txt, False)\n",
    "ev = []\n",
    "for i in range(len(evidences)):\n",
    "    ev.append(evidences[i].split() + [' | '] + ner[i] + [' | '] + pos[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence sililarity step\n",
    "In this section we apply a TfidfVectorizer with different similarity measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:53<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from Levenshtein import distance as levenshtein_distance\n",
    "import time\n",
    "from scipy.sparse.linalg import norm\n",
    "tvec = TfidfVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Timer\n",
    "st  = time.time()\n",
    "# Instanciate lists\n",
    "top = []\n",
    "evs = pd.DataFrame([i for i,j in evidence.items()], columns=['evidences'])\n",
    "# Fit and Transform evidences\n",
    "eviden = tvec.fit_transform([' '.join(i) for i in ev])\n",
    "print(f'{time.time()-st:0.2f}')\n",
    "# Iterate claims and evaluate similarity\n",
    "for i in tqdm(range(len(claim))):\n",
    "    claims = tvec.transform([claim[i]])\n",
    "    # Levenshtein Distance\n",
    "    # sim = [levenshtein_distance(claim[i], ev[j]) for j in range(len(ev))]\n",
    "    # Cos Similarity\n",
    "    sim = (np.dot(claims, eviden.T)/(norm(claims)*norm(eviden))).toarray()\n",
    "    # Jaccard Similarity\n",
    "    # sim = (claims.multiply(eviden).sum(axis=1)) / (claims.sum(axis=1) + eviden.sum(axis=1) - claims.multiply(eviden).sum(axis=1))\n",
    "    # Get top 5\n",
    "    df_ = evs.copy()\n",
    "    df_['sim'] = sim[0]\n",
    "    top.append(df_.sort_values(['sim'], ascending=False)['evidences'][:3].values)\n",
    "ds = df_dev.copy()\n",
    "ds['top'] = top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0685\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "for idx, row in ds.iterrows():\n",
    "    pred = [1 if top in row['evidences'] else 0 for top in row['top']]\n",
    "    TP = sum(pred)/len(row['evidences'])\n",
    "    FP = len(row['top']) - sum(pred)\n",
    "    FN = len(row['evidences']) - sum(pred)\n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    f1.append(2*prec*rec/(prec+rec+1e-10))\n",
    "print(f'F1 Score: {np.mean(f1):0.4f}')\n",
    "# F1 Score: 0.0705"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dev claims\n",
    "with open('../data/test-claims-unlabelled.json', 'r') as f:\n",
    "    df_test = pd.DataFrame(json.load(f)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.copy()\n",
    "# Claim\n",
    "claim = feature_selection(df['claim_text'], True)\n",
    "claim = [' '.join(i) for i in claim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:50<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Timer\n",
    "st  = time.time()\n",
    "# Instanciate lists\n",
    "top = []\n",
    "evs = pd.DataFrame([i for i,j in evidence.items()], columns=['evidences'])\n",
    "# Fit and Transform evidences\n",
    "eviden = tvec.fit_transform([' '.join(i) for i in ev])\n",
    "print(f'{time.time()-st:0.2f}')\n",
    "# Iterate claims and evaluate similarity\n",
    "for i in tqdm(range(len(claim))):\n",
    "    claims = tvec.transform([claim[i]])\n",
    "    # Cos Similarity\n",
    "    sim = (np.dot(claims, eviden.T)/(norm(claims)*norm(eviden))).toarray()\n",
    "    # Get top 5\n",
    "    df_ = evs.copy()\n",
    "    df_['sim'] = sim.reshape(-1,1)\n",
    "    top.append(df_.sort_values(['sim'], ascending=False)['evidences'][:5].values.tolist())\n",
    "ds = df_test.copy()\n",
    "ds['top'] = top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "labels = list(df_dev['claim_label'].unique())\n",
    "# ds\n",
    "ds['claim_label'] = [random.choice(labels) for i in range(ds.shape[0])]\n",
    "ds = ds.iloc[:,[0,2,1]]\n",
    "ds.columns = ['claim_text', 'claim_label', 'evidences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dct = ds.to_dict(orient='index')\n",
    "with open('../Models/Test files/test-output.json', 'w') as f:\n",
    "    json.dump(ts_dct, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
