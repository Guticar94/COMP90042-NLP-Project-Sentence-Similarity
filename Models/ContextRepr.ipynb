{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train claims\n",
    "with open('../data/train-claims.json', 'r') as f:\n",
    "    df_train = pd.DataFrame(json.load(f)).transpose()\n",
    "\n",
    "# Read dev claims\n",
    "with open('../data/dev-claims.json', 'r') as f:\n",
    "    df_dev = pd.DataFrame(json.load(f)).transpose()\n",
    "\n",
    "# Read evidence\n",
    "with open('../data/evidence.json', 'r') as f:\n",
    "    evidence = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.\n",
      "DISPUTED\n",
      "['evidence-442946', 'evidence-1194317', 'evidence-12171']\n",
      "\n",
      "evidence-442946: At very high concentrations (100 times atmospheric concentration, or greater), carbon dioxide can be toxic to animal life, so raising the concentration to 10,000 ppm (1%) or higher for several hours will eliminate pests such as whiteflies and spider mites in a greenhouse.\n",
      "evidence-1194317: Plants can grow as much as 50 percent faster in concentrations of 1,000 ppm CO 2 when compared with ambient conditions, though this assumes no change in climate and no limitation on other nutrients.\n",
      "evidence-12171: Higher carbon dioxide concentrations will favourably affect plant growth and demand for water.\n"
     ]
    }
   ],
   "source": [
    "print(df_train.iloc[0,0])\n",
    "print(df_train.iloc[0,1])\n",
    "print(df_train.iloc[0,2])\n",
    "print()\n",
    "print(f'{df_train.iloc[0,2][0]}: {evidence[df_train.iloc[0,2][0]]}')\n",
    "print(f'{df_train.iloc[0,2][1]}: {evidence[df_train.iloc[0,2][1]]}')\n",
    "print(f'{df_train.iloc[0,2][2]}: {evidence[df_train.iloc[0,2][2]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to lower\n",
    "ev = [str.lower(j) for i,j in evidence.items()][:15000]\n",
    "# Drop non alphabetical characters\n",
    "ev = [' '.join([w for w in seq.split() if re.match('^[a-z0-9]+$', w)]) for seq in ev]\n",
    "dv = [txt.split() for txt in df_train['claim_text'].values[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class tokenizer:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words to idx\n",
    "sequence = tokenizer()\n",
    "[sequence.addSentence(sentence) for sentence in ev]\n",
    "[sequence.addSentence(' '.join(dv[0]))]\n",
    "\n",
    "# Add BOS and EOS\n",
    "num_evid = [[0] + [sequence.word2index[j] for j in i.split()] + [1] for i in ev]\n",
    "num_quer = [0] + [sequence.word2index[w] for w in dv[0]] + [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data to tensor batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.text = texts\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        texts = torch.tensor(self.text[idx])\n",
    "        labels = torch.tensor(self.labels[idx]).reshape(-1,1)\n",
    "        return texts, labels\n",
    "    \n",
    "# Define collate (pre_process) function\n",
    "def collate_batch(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = nn.utils.rnn.pad_sequence(texts, batch_first=True).to(device)\n",
    "    return texts, labels\n",
    "\n",
    "# Instanciate DataLoader\n",
    "bs = 32\n",
    "tr_ds = Dataset(num_evid, range(len(num_evid)))\n",
    "dv_ds = Dataset(num_quer, range(len(num_quer)))\n",
    "\n",
    "tr_dl = DataLoader(tr_ds, batch_size=bs, collate_fn=collate_batch)\n",
    "dv_dl = DataLoader(dv_ds, batch_size=bs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> 2.1 Positional encoding to embed the data</h3></center>\n",
    "\n",
    "<center><img src=../Images/pos_encoder.png alt=\"drawing\" width=\"300\"></center>\n",
    "\n",
    "<center>Details on:</center>\n",
    "<center><a href=\"https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/\"><ph>A Gentle Introduction to Positional Encoding in Transformer Models</ph></a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "max_len_ = max([len(i) for i in num_evid]) # Maximum number of tokens in a sentence\n",
    "# Positional embeding function\n",
    "class positionalEmbeding(nn.Module):\n",
    "    def __init__(self, embedding_dim, drop = 0.2, max_len = max_len_):\n",
    "        # Inputs:\n",
    "        # embedding_dim: Length of input embeding\n",
    "        # max_len: Max number of tokens in an input sentence\n",
    "        # Return: Positional Embeding Matrix\n",
    "        super(positionalEmbeding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=drop)                                                                           # Dropout layer\n",
    "        \n",
    "        # Positional embeding matrix \n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)                                         # Positional increasing vector [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim))      # Division term for the sin/cos functions\n",
    "        pe = torch.zeros(max_len, embedding_dim)                                                                    # Matrix of 0's [max_len, embedding_dim]\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)                                                                # 0::2 means starting with index 0, step = 2\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)                                                                # 1::2 means starting with index 1, step = 2\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)                                                                        # Resize pos encoder [max_len, 1, embedding_dim]\n",
    "        self.register_buffer('pe', pe)                                                                              # Adds pos encoder to the model state_dict\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input:\n",
    "        # x: Embeding matrix [batch_size, text_length, embedding_dim]\n",
    "        x = x + self.pe[:x.size(0), :x.size(1)]      # Sum the position embeding\n",
    "        return self.dropout(x)              # Apply dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> 2.2 Multihead attention</h3></center>\n",
    "<center><img src=../Images/attention.png alt=\"drawing\" width=\"600\"></center>\n",
    "\n",
    "<center>Details on:</center>\n",
    "<center><a href=\"https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\"><ph>Build your own Transformer from scratch using Pytorch</ph></a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        assert embedding_dim % num_heads == 0, \"in_size must be divisible by num_heads\"\n",
    "\n",
    "        self.embedding_dim = embedding_dim                      # Embeding input size\n",
    "        self.num_heads = num_heads                              # Num heads of multihead attention model\n",
    "        self.head_dim = embedding_dim // num_heads              # Embedding parameters for each head\n",
    "        \n",
    "        # Instanciate weights\n",
    "        self.W_q = nn.Linear(embedding_dim, embedding_dim)      # Query weights\n",
    "        self.W_k = nn.Linear(embedding_dim, embedding_dim)      # Key weights\n",
    "        self.W_v = nn.Linear(embedding_dim, embedding_dim)      # Values weights\n",
    "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    # scaled_dot_product_attention\n",
    "    def dot_prd_attn(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)   # MatMult (Q*K)\n",
    "        if mask is not None: attn_scores = attn_scores.masked_fill(mask == 0, -1e9)     # Masking (Optional)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)                                 # Softmax\n",
    "        output = torch.matmul(attn_probs, V)                                            # MatMult (Probs*V)\n",
    "        return output\n",
    "    \n",
    "    # Function to split attention heads\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, embedding_dim = x.size()\n",
    "        return x.view(batch_size, self.num_heads, seq_length, self.head_dim)\n",
    "    # Function to join attention heads\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, head_dim = x.size()\n",
    "        return x.view(batch_size, seq_length, self.embedding_dim)\n",
    "    \n",
    "    def forward(self, x, mask = None):\n",
    "        # Weights linear pass (Random inicialization) + Split heads\n",
    "        Q = self.split_heads(self.W_q(x))\n",
    "        K = self.split_heads(self.W_k(x))\n",
    "        V = self.split_heads(self.W_v(x))\n",
    "        # Multihead attention\n",
    "        attn = self.dot_prd_attn(Q, K, V, mask)                 # scaled_dot_product_attention\n",
    "        attn = self.combine_heads(attn)                         # Concat heads\n",
    "        attn = self.linear(attn)                                # Linear pass\n",
    "        return attn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> 2.5 Transformer model (Passage Ranking)</h3></center>\n",
    "<center>Source papers:</center>\n",
    "<center><a href=\"https://arxiv.org/pdf/1706.03762\"><ph>Attention Is All You Need</ph></a></center>\n",
    "<center><a href=\"https://arxiv.org/pdf/1706.03762\"><ph>Text and Code Embeddings by Contrastive Pre-Training</ph></a></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Encoder:</center>\n",
    "<center><img src=../Images/encoder.png alt=\"drawing\" width=\"300\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder class based \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                vocab_size,                            # Size of vocabulary\n",
    "                embedding_dim,                         # Embedding dimension\n",
    "                n_head,                                # Number of heads  in the multihead attention model\n",
    "                hidden_dim,                            # Hiden dims for the feed forward pass\n",
    "                dropout = 0.5):\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dim)                  # Embeding layer\n",
    "        self.pos_encoder = positionalEmbeding(embedding_dim, dropout)           # Positional embeding\n",
    "        self.multihead = MultiHeadAttention(embedding_dim, n_head)              # Multihead attention layer\n",
    "        self.normalization = nn.LayerNorm(embedding_dim)                        # Normalization layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(embedding_dim, 1)                               # Output layer\n",
    "\n",
    "        # Feed forward pass\n",
    "        self.feed_forward = nn.Sequential()\n",
    "        self.feed_forward.add_module('fc1', nn.Linear(embedding_dim, hidden_dim))\n",
    "        self.feed_forward.add_module('relu', nn.ReLU())\n",
    "        self.feed_forward.add_module('fc2', nn.Linear(hidden_dim, embedding_dim))\n",
    "\n",
    "    def forward(self, text):\n",
    "        encoder = self.encoder(text) * math.sqrt(self.embedding_dim)            # Encode imput text [batch_size, text_length, embedding_dim]\n",
    "        pos_enc = self.pos_encoder(encoder)                                     # Reurn pos encoder [batch_size, text_length, embedding_dim]\n",
    "        attn = self.multihead(pos_enc)                                          # Multihead encoder\n",
    "        normal = self.normalization(text.unsqueeze(2) + self.dropout(attn))     # Add & Normalize pass #1  UNSQUEEZE\n",
    "        forward = self.feed_forward(normal)                                     # Feed Forward pass\n",
    "        encoded = self.normalization(normal + self.dropout(forward))            # Add & Normalize pass #2\n",
    "        lin_vec = self.linear(encoded)\n",
    "        return lin_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # Encoder is a stack of N encoder layers. \n",
    "    def __init__(self, encoder_layer, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for i in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, text, mask = None, src_key_padding_mask = None):\n",
    "        output = text\n",
    "        for layer in self.layers:\n",
    "            output = layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max([max(i) for i in num_evid]) + max(num_quer)\n",
    "embedding_dim = 300\n",
    "n_head = 2\n",
    "dropout = 0.5\n",
    "hidden_dim = 2048\n",
    "num_layers = 2\n",
    "encoder_layer = EncoderLayer(vocab_size, embedding_dim, n_head, hidden_dim, dropout).to(device)\n",
    "encoder = Encoder(encoder_layer, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:08<00:00, 57.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy.linalg import norm\n",
    "cos_sim = []\n",
    "y = encoder_layer(next(iter(dv_dl))[0].unsqueeze(1)).reshape(-1).detach().numpy()\n",
    "for x, _ in tqdm(tr_dl):\n",
    "    enc = encoder_layer(x)\n",
    "    for line in enc:\n",
    "        X = line.reshape(-1).detach().numpy()\n",
    "        cos_sim.append(np.dot(X[:len(y)], y[:len(X)])/(norm(X)*norm(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>Evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>0.567922</td>\n",
       "      <td>within countries as differing political moveme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>0.566776</td>\n",
       "      <td>or sitamun was a princess of the early eightee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>0.535906</td>\n",
       "      <td>geese are waterfowl belonging to the tribe ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>0.517724</td>\n",
       "      <td>the galaxy y duos is a mobile phone from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>0.494271</td>\n",
       "      <td>jacques schotte september was a belgian psychi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>-0.541321</td>\n",
       "      <td>casley never played for torquay league team in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8748</th>\n",
       "      <td>-0.550421</td>\n",
       "      <td>while the characters and instances in the movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11473</th>\n",
       "      <td>-0.575943</td>\n",
       "      <td>momofuku is a cookbook by american chef david ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>-0.587998</td>\n",
       "      <td>ross mccloud 1819 august was a california pion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13463</th>\n",
       "      <td>-0.625665</td>\n",
       "      <td>it is a teaching hospital and major provincial...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       similarity                                           Evidence\n",
       "8048     0.567922  within countries as differing political moveme...\n",
       "13066    0.566776  or sitamun was a princess of the early eightee...\n",
       "6668     0.535906  geese are waterfowl belonging to the tribe ans...\n",
       "7129     0.517724           the galaxy y duos is a mobile phone from\n",
       "11642    0.494271  jacques schotte september was a belgian psychi...\n",
       "...           ...                                                ...\n",
       "381     -0.541321  casley never played for torquay league team in...\n",
       "8748    -0.550421  while the characters and instances in the movi...\n",
       "11473   -0.575943  momofuku is a cookbook by american chef david ...\n",
       "11450   -0.587998  ross mccloud 1819 august was a california pion...\n",
       "13463   -0.625665  it is a teaching hospital and major provincial...\n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cos_sim, columns=['similarity'])\n",
    "df['Evidence'] = ev[:15000]\n",
    "df.sort_values('similarity', ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['claim_text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>Evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12171</th>\n",
       "      <td>-0.201789</td>\n",
       "      <td>higher carbon dioxide concentrations will favo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       similarity                                           Evidence\n",
       "12171   -0.201789  higher carbon dioxide concentrations will favo..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index == 12171]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(dv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_39035/3878134485.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_train['evidences'][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['evidence-442946', 'evidence-1194317', 'evidence-12171']"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['evidences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4933"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(sequence.word2index.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
