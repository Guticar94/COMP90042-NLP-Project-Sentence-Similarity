{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evidence dataset\n",
    "# Read evidence\n",
    "with open('../data/evidence.json', 'r') as f:\n",
    "    evidence = json.load(f)\n",
    "eviden = pd.DataFrame.from_dict(evidence, orient='index', columns=['evidence'])\n",
    "\n",
    "# Read dev claims\n",
    "with open('../data/dev-claims.json', 'r') as f:\n",
    "    df_dev = pd.DataFrame(json.load(f)).transpose()\n",
    "\n",
    "# Load encoded evidence set\n",
    "with open('../data/SBERT_2/encoded_evidence.json', 'rb') as f:\n",
    "    enc_ev = np.load(f)\n",
    "# Load encoded dev set\n",
    "with open('../data/SBERT_2/encoded_dev_claims.json', 'rb') as f:\n",
    "    enc_dv = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 154 iterantions\n",
      "1 of 154 iterantions\n",
      "2 of 154 iterantions\n",
      "3 of 154 iterantions\n",
      "4 of 154 iterantions\n",
      "5 of 154 iterantions\n",
      "6 of 154 iterantions\n",
      "7 of 154 iterantions\n",
      "8 of 154 iterantions\n",
      "9 of 154 iterantions\n",
      "10 of 154 iterantions\n",
      "11 of 154 iterantions\n",
      "12 of 154 iterantions\n",
      "13 of 154 iterantions\n",
      "14 of 154 iterantions\n",
      "15 of 154 iterantions\n",
      "16 of 154 iterantions\n",
      "17 of 154 iterantions\n",
      "18 of 154 iterantions\n",
      "19 of 154 iterantions\n",
      "20 of 154 iterantions\n",
      "21 of 154 iterantions\n",
      "22 of 154 iterantions\n",
      "23 of 154 iterantions\n",
      "24 of 154 iterantions\n",
      "25 of 154 iterantions\n",
      "26 of 154 iterantions\n",
      "27 of 154 iterantions\n",
      "28 of 154 iterantions\n",
      "29 of 154 iterantions\n",
      "30 of 154 iterantions\n",
      "31 of 154 iterantions\n",
      "32 of 154 iterantions\n",
      "33 of 154 iterantions\n",
      "34 of 154 iterantions\n",
      "35 of 154 iterantions\n",
      "36 of 154 iterantions\n",
      "37 of 154 iterantions\n",
      "38 of 154 iterantions\n",
      "39 of 154 iterantions\n",
      "40 of 154 iterantions\n",
      "41 of 154 iterantions\n",
      "42 of 154 iterantions\n",
      "43 of 154 iterantions\n",
      "44 of 154 iterantions\n",
      "45 of 154 iterantions\n",
      "46 of 154 iterantions\n",
      "47 of 154 iterantions\n",
      "48 of 154 iterantions\n",
      "49 of 154 iterantions\n",
      "50 of 154 iterantions\n",
      "51 of 154 iterantions\n",
      "52 of 154 iterantions\n",
      "53 of 154 iterantions\n",
      "54 of 154 iterantions\n",
      "55 of 154 iterantions\n",
      "56 of 154 iterantions\n",
      "57 of 154 iterantions\n",
      "58 of 154 iterantions\n",
      "59 of 154 iterantions\n",
      "60 of 154 iterantions\n",
      "61 of 154 iterantions\n",
      "62 of 154 iterantions\n",
      "63 of 154 iterantions\n",
      "64 of 154 iterantions\n",
      "65 of 154 iterantions\n",
      "66 of 154 iterantions\n",
      "67 of 154 iterantions\n",
      "68 of 154 iterantions\n",
      "69 of 154 iterantions\n",
      "70 of 154 iterantions\n",
      "71 of 154 iterantions\n",
      "72 of 154 iterantions\n",
      "73 of 154 iterantions\n",
      "74 of 154 iterantions\n",
      "75 of 154 iterantions\n",
      "76 of 154 iterantions\n",
      "77 of 154 iterantions\n",
      "78 of 154 iterantions\n",
      "79 of 154 iterantions\n",
      "80 of 154 iterantions\n",
      "81 of 154 iterantions\n",
      "82 of 154 iterantions\n",
      "83 of 154 iterantions\n",
      "84 of 154 iterantions\n",
      "85 of 154 iterantions\n",
      "86 of 154 iterantions\n",
      "87 of 154 iterantions\n",
      "88 of 154 iterantions\n",
      "89 of 154 iterantions\n",
      "90 of 154 iterantions\n",
      "91 of 154 iterantions\n",
      "92 of 154 iterantions\n",
      "93 of 154 iterantions\n",
      "94 of 154 iterantions\n",
      "95 of 154 iterantions\n",
      "96 of 154 iterantions\n",
      "97 of 154 iterantions\n",
      "98 of 154 iterantions\n",
      "99 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 of 154 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/388008328.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "tot = enc_dv.shape[0]\n",
    "dv_sim = []\n",
    "dv_sim_ = []\n",
    "df = pd.Series(np.array(eviden.index)).reset_index(name='id').drop(['index'], axis=1)\n",
    "for i in range(tot):\n",
    "    print(f'{i} of {tot} iterantions')\n",
    "    similarity = cos(torch.from_numpy(enc_ev), torch.from_numpy(enc_dv[i]))\n",
    "    df[df_dev.index[i]] = similarity.detach().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim-752</th>\n",
       "      <th>claim-375</th>\n",
       "      <th>claim-1266</th>\n",
       "      <th>claim-871</th>\n",
       "      <th>claim-2164</th>\n",
       "      <th>claim-1607</th>\n",
       "      <th>claim-761</th>\n",
       "      <th>claim-1718</th>\n",
       "      <th>claim-1273</th>\n",
       "      <th>...</th>\n",
       "      <th>claim-530</th>\n",
       "      <th>claim-2979</th>\n",
       "      <th>claim-665</th>\n",
       "      <th>claim-199</th>\n",
       "      <th>claim-490</th>\n",
       "      <th>claim-2400</th>\n",
       "      <th>claim-204</th>\n",
       "      <th>claim-1426</th>\n",
       "      <th>claim-698</th>\n",
       "      <th>claim-1021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidence-0</td>\n",
       "      <td>0.920275</td>\n",
       "      <td>0.655468</td>\n",
       "      <td>0.985084</td>\n",
       "      <td>0.527866</td>\n",
       "      <td>0.733992</td>\n",
       "      <td>0.647238</td>\n",
       "      <td>-0.155715</td>\n",
       "      <td>-0.462399</td>\n",
       "      <td>0.672091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414640</td>\n",
       "      <td>0.618615</td>\n",
       "      <td>0.848770</td>\n",
       "      <td>0.651630</td>\n",
       "      <td>0.605739</td>\n",
       "      <td>0.814369</td>\n",
       "      <td>0.689088</td>\n",
       "      <td>0.800785</td>\n",
       "      <td>0.742398</td>\n",
       "      <td>0.981039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evidence-1</td>\n",
       "      <td>-0.440379</td>\n",
       "      <td>-0.982104</td>\n",
       "      <td>-0.768651</td>\n",
       "      <td>0.163122</td>\n",
       "      <td>-0.984385</td>\n",
       "      <td>-0.979251</td>\n",
       "      <td>0.769822</td>\n",
       "      <td>0.912332</td>\n",
       "      <td>-0.984241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908974</td>\n",
       "      <td>-0.972980</td>\n",
       "      <td>-0.960200</td>\n",
       "      <td>-0.974219</td>\n",
       "      <td>0.089181</td>\n",
       "      <td>-0.976255</td>\n",
       "      <td>-0.984056</td>\n",
       "      <td>-0.909748</td>\n",
       "      <td>-0.988843</td>\n",
       "      <td>-0.776417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evidence-2</td>\n",
       "      <td>-0.371895</td>\n",
       "      <td>-0.969249</td>\n",
       "      <td>-0.715300</td>\n",
       "      <td>0.298355</td>\n",
       "      <td>-0.965718</td>\n",
       "      <td>-0.954089</td>\n",
       "      <td>0.831383</td>\n",
       "      <td>0.968812</td>\n",
       "      <td>-0.975579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906314</td>\n",
       "      <td>-0.963241</td>\n",
       "      <td>-0.931879</td>\n",
       "      <td>-0.932708</td>\n",
       "      <td>0.158093</td>\n",
       "      <td>-0.925239</td>\n",
       "      <td>-0.972153</td>\n",
       "      <td>-0.824171</td>\n",
       "      <td>-0.967376</td>\n",
       "      <td>-0.684735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evidence-3</td>\n",
       "      <td>-0.179234</td>\n",
       "      <td>0.766087</td>\n",
       "      <td>0.173368</td>\n",
       "      <td>-0.713741</td>\n",
       "      <td>0.700091</td>\n",
       "      <td>0.763673</td>\n",
       "      <td>-0.784633</td>\n",
       "      <td>-0.789259</td>\n",
       "      <td>0.748830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816271</td>\n",
       "      <td>0.793544</td>\n",
       "      <td>0.547288</td>\n",
       "      <td>0.739090</td>\n",
       "      <td>-0.598837</td>\n",
       "      <td>0.583458</td>\n",
       "      <td>0.738751</td>\n",
       "      <td>0.474578</td>\n",
       "      <td>0.682050</td>\n",
       "      <td>0.152342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evidence-4</td>\n",
       "      <td>-0.115849</td>\n",
       "      <td>-0.906719</td>\n",
       "      <td>-0.488031</td>\n",
       "      <td>0.376394</td>\n",
       "      <td>-0.875274</td>\n",
       "      <td>-0.923123</td>\n",
       "      <td>0.835778</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>-0.892138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959892</td>\n",
       "      <td>-0.912055</td>\n",
       "      <td>-0.788011</td>\n",
       "      <td>-0.931081</td>\n",
       "      <td>0.377254</td>\n",
       "      <td>-0.842622</td>\n",
       "      <td>-0.888571</td>\n",
       "      <td>-0.795488</td>\n",
       "      <td>-0.870927</td>\n",
       "      <td>-0.531699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208822</th>\n",
       "      <td>evidence-1208822</td>\n",
       "      <td>0.901981</td>\n",
       "      <td>0.696361</td>\n",
       "      <td>0.979610</td>\n",
       "      <td>0.459796</td>\n",
       "      <td>0.773904</td>\n",
       "      <td>0.690556</td>\n",
       "      <td>-0.228903</td>\n",
       "      <td>-0.471098</td>\n",
       "      <td>0.711938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510098</td>\n",
       "      <td>0.662426</td>\n",
       "      <td>0.879611</td>\n",
       "      <td>0.712044</td>\n",
       "      <td>0.569121</td>\n",
       "      <td>0.837853</td>\n",
       "      <td>0.728846</td>\n",
       "      <td>0.864888</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>0.964133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208823</th>\n",
       "      <td>evidence-1208823</td>\n",
       "      <td>-0.299017</td>\n",
       "      <td>-0.982896</td>\n",
       "      <td>-0.655169</td>\n",
       "      <td>0.347981</td>\n",
       "      <td>-0.967468</td>\n",
       "      <td>-0.977084</td>\n",
       "      <td>0.862365</td>\n",
       "      <td>0.943150</td>\n",
       "      <td>-0.981964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961122</td>\n",
       "      <td>-0.981042</td>\n",
       "      <td>-0.911603</td>\n",
       "      <td>-0.970887</td>\n",
       "      <td>0.243140</td>\n",
       "      <td>-0.927029</td>\n",
       "      <td>-0.978123</td>\n",
       "      <td>-0.841433</td>\n",
       "      <td>-0.968092</td>\n",
       "      <td>-0.641716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208824</th>\n",
       "      <td>evidence-1208824</td>\n",
       "      <td>-0.217660</td>\n",
       "      <td>-0.971217</td>\n",
       "      <td>-0.590341</td>\n",
       "      <td>0.400211</td>\n",
       "      <td>-0.948799</td>\n",
       "      <td>-0.970840</td>\n",
       "      <td>0.874355</td>\n",
       "      <td>0.942032</td>\n",
       "      <td>-0.966673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978526</td>\n",
       "      <td>-0.975015</td>\n",
       "      <td>-0.876475</td>\n",
       "      <td>-0.960109</td>\n",
       "      <td>0.319018</td>\n",
       "      <td>-0.896225</td>\n",
       "      <td>-0.963287</td>\n",
       "      <td>-0.821100</td>\n",
       "      <td>-0.945045</td>\n",
       "      <td>-0.594891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208825</th>\n",
       "      <td>evidence-1208825</td>\n",
       "      <td>0.304737</td>\n",
       "      <td>-0.688599</td>\n",
       "      <td>-0.079199</td>\n",
       "      <td>0.735092</td>\n",
       "      <td>-0.611867</td>\n",
       "      <td>-0.688757</td>\n",
       "      <td>0.840675</td>\n",
       "      <td>0.793888</td>\n",
       "      <td>-0.666911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773926</td>\n",
       "      <td>-0.705919</td>\n",
       "      <td>-0.458687</td>\n",
       "      <td>-0.664151</td>\n",
       "      <td>0.731353</td>\n",
       "      <td>-0.519207</td>\n",
       "      <td>-0.654781</td>\n",
       "      <td>-0.359091</td>\n",
       "      <td>-0.604218</td>\n",
       "      <td>-0.075778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208826</th>\n",
       "      <td>evidence-1208826</td>\n",
       "      <td>0.757811</td>\n",
       "      <td>0.287833</td>\n",
       "      <td>0.685828</td>\n",
       "      <td>0.704830</td>\n",
       "      <td>0.370235</td>\n",
       "      <td>0.307901</td>\n",
       "      <td>0.201907</td>\n",
       "      <td>0.052783</td>\n",
       "      <td>0.287882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160517</td>\n",
       "      <td>0.258564</td>\n",
       "      <td>0.487372</td>\n",
       "      <td>0.372261</td>\n",
       "      <td>0.692870</td>\n",
       "      <td>0.474968</td>\n",
       "      <td>0.309413</td>\n",
       "      <td>0.596652</td>\n",
       "      <td>0.365475</td>\n",
       "      <td>0.720421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1208827 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  claim-752  claim-375  claim-1266  claim-871  \\\n",
       "0              evidence-0   0.920275   0.655468    0.985084   0.527866   \n",
       "1              evidence-1  -0.440379  -0.982104   -0.768651   0.163122   \n",
       "2              evidence-2  -0.371895  -0.969249   -0.715300   0.298355   \n",
       "3              evidence-3  -0.179234   0.766087    0.173368  -0.713741   \n",
       "4              evidence-4  -0.115849  -0.906719   -0.488031   0.376394   \n",
       "...                   ...        ...        ...         ...        ...   \n",
       "1208822  evidence-1208822   0.901981   0.696361    0.979610   0.459796   \n",
       "1208823  evidence-1208823  -0.299017  -0.982896   -0.655169   0.347981   \n",
       "1208824  evidence-1208824  -0.217660  -0.971217   -0.590341   0.400211   \n",
       "1208825  evidence-1208825   0.304737  -0.688599   -0.079199   0.735092   \n",
       "1208826  evidence-1208826   0.757811   0.287833    0.685828   0.704830   \n",
       "\n",
       "         claim-2164  claim-1607  claim-761  claim-1718  claim-1273  ...  \\\n",
       "0          0.733992    0.647238  -0.155715   -0.462399    0.672091  ...   \n",
       "1         -0.984385   -0.979251   0.769822    0.912332   -0.984241  ...   \n",
       "2         -0.965718   -0.954089   0.831383    0.968812   -0.975579  ...   \n",
       "3          0.700091    0.763673  -0.784633   -0.789259    0.748830  ...   \n",
       "4         -0.875274   -0.923123   0.835778    0.842307   -0.892138  ...   \n",
       "...             ...         ...        ...         ...         ...  ...   \n",
       "1208822    0.773904    0.690556  -0.228903   -0.471098    0.711938  ...   \n",
       "1208823   -0.967468   -0.977084   0.862365    0.943150   -0.981964  ...   \n",
       "1208824   -0.948799   -0.970840   0.874355    0.942032   -0.966673  ...   \n",
       "1208825   -0.611867   -0.688757   0.840675    0.793888   -0.666911  ...   \n",
       "1208826    0.370235    0.307901   0.201907    0.052783    0.287882  ...   \n",
       "\n",
       "         claim-530  claim-2979  claim-665  claim-199  claim-490  claim-2400  \\\n",
       "0        -0.414640    0.618615   0.848770   0.651630   0.605739    0.814369   \n",
       "1         0.908974   -0.972980  -0.960200  -0.974219   0.089181   -0.976255   \n",
       "2         0.906314   -0.963241  -0.931879  -0.932708   0.158093   -0.925239   \n",
       "3        -0.816271    0.793544   0.547288   0.739090  -0.598837    0.583458   \n",
       "4         0.959892   -0.912055  -0.788011  -0.931081   0.377254   -0.842622   \n",
       "...            ...         ...        ...        ...        ...         ...   \n",
       "1208822  -0.510098    0.662426   0.879611   0.712044   0.569121    0.837853   \n",
       "1208823   0.961122   -0.981042  -0.911603  -0.970887   0.243140   -0.927029   \n",
       "1208824   0.978526   -0.975015  -0.876475  -0.960109   0.319018   -0.896225   \n",
       "1208825   0.773926   -0.705919  -0.458687  -0.664151   0.731353   -0.519207   \n",
       "1208826  -0.160517    0.258564   0.487372   0.372261   0.692870    0.474968   \n",
       "\n",
       "         claim-204  claim-1426  claim-698  claim-1021  \n",
       "0         0.689088    0.800785   0.742398    0.981039  \n",
       "1        -0.984056   -0.909748  -0.988843   -0.776417  \n",
       "2        -0.972153   -0.824171  -0.967376   -0.684735  \n",
       "3         0.738751    0.474578   0.682050    0.152342  \n",
       "4        -0.888571   -0.795488  -0.870927   -0.531699  \n",
       "...            ...         ...        ...         ...  \n",
       "1208822   0.728846    0.864888   0.777982    0.964133  \n",
       "1208823  -0.978123   -0.841433  -0.968092   -0.641716  \n",
       "1208824  -0.963287   -0.821100  -0.945045   -0.594891  \n",
       "1208825  -0.654781   -0.359091  -0.604218   -0.075778  \n",
       "1208826   0.309413    0.596652   0.365475    0.720421  \n",
       "\n",
       "[1208827 rows x 155 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/SBERT_2/sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 990 F1: 0.0001251826994173842\n",
      "thresh: 993 F1: 0.00014719771697847464\n",
      "thresh: 996 F1: 0.00016811728171091595\n",
      "thresh: 999 F1: 0.0004276801047330198\n"
     ]
    }
   ],
   "source": [
    "f_score = {}\n",
    "for thresh in range(990,1000, 3):\n",
    "    precision, recall, F1 = [], [], []\n",
    "    for claim in df_dev.index:\n",
    "        ds = df.set_index('id').loc[:, [claim]] \n",
    "        ds = ds[ds[claim] >= thresh/1000]\n",
    "        TP = ds[ds.index.isin(df_dev.loc[claim, 'evidences'])].shape[0]\n",
    "        FP = ds.shape[0]-TP\n",
    "        FN = len(df_dev.loc[claim, 'evidences']) - TP\n",
    "\n",
    "        precision = TP/(TP+FP + 1E-10)\n",
    "        recall = TP/(TP+FN + 1E-10)\n",
    "        F1.append((2 * precision * recall)/(precision + recall + 1E-10))\n",
    "    mn = np.mean(F1)\n",
    "    f_score[thresh] = mn\n",
    "    print(f'thresh: {thresh} F1: {mn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.9999 F1: 0.000851058613136259\n"
     ]
    }
   ],
   "source": [
    "f_score = {}\n",
    "for thresh in range(9999,10000):\n",
    "    precision, recall, F1 = [], [], []\n",
    "    for claim in df_dev.index:\n",
    "        ds = df.set_index('id').loc[:, [claim]] \n",
    "        ds = ds[ds[claim] >= thresh/10000]\n",
    "        TP = ds[ds.index.isin(df_dev.loc[claim, 'evidences'])].shape[0]\n",
    "        FP = ds.shape[0]-TP\n",
    "        FN = len(df_dev.loc[claim, 'evidences']) - TP\n",
    "\n",
    "        precision = TP/(TP+FP + 1E-10)\n",
    "        recall = TP/(TP+FN + 1E-10)\n",
    "        F1.append((2 * precision * recall)/(precision + recall + 1E-10))\n",
    "    mn = np.mean(F1)\n",
    "    f_score[thresh] = mn\n",
    "    print(f'thresh: {thresh/10000} F1: {mn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dev claims\n",
    "with open('../data/test-claims-unlabelled.json', 'r') as f:\n",
    "    df_test = pd.DataFrame(json.load(f)).transpose()\n",
    "\n",
    "\n",
    "# Load encoded test set\n",
    "with open('../data/SBERT_2/encoded_ts_claims.json', 'rb') as f:\n",
    "    enc_ts = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 153 iterantions\n",
      "1 of 153 iterantions\n",
      "2 of 153 iterantions\n",
      "3 of 153 iterantions\n",
      "4 of 153 iterantions\n",
      "5 of 153 iterantions\n",
      "6 of 153 iterantions\n",
      "7 of 153 iterantions\n",
      "8 of 153 iterantions\n",
      "9 of 153 iterantions\n",
      "10 of 153 iterantions\n",
      "11 of 153 iterantions\n",
      "12 of 153 iterantions\n",
      "13 of 153 iterantions\n",
      "14 of 153 iterantions\n",
      "15 of 153 iterantions\n",
      "16 of 153 iterantions\n",
      "17 of 153 iterantions\n",
      "18 of 153 iterantions\n",
      "19 of 153 iterantions\n",
      "20 of 153 iterantions\n",
      "21 of 153 iterantions\n",
      "22 of 153 iterantions\n",
      "23 of 153 iterantions\n",
      "24 of 153 iterantions\n",
      "25 of 153 iterantions\n",
      "26 of 153 iterantions\n",
      "27 of 153 iterantions\n",
      "28 of 153 iterantions\n",
      "29 of 153 iterantions\n",
      "30 of 153 iterantions\n",
      "31 of 153 iterantions\n",
      "32 of 153 iterantions\n",
      "33 of 153 iterantions\n",
      "34 of 153 iterantions\n",
      "35 of 153 iterantions\n",
      "36 of 153 iterantions\n",
      "37 of 153 iterantions\n",
      "38 of 153 iterantions\n",
      "39 of 153 iterantions\n",
      "40 of 153 iterantions\n",
      "41 of 153 iterantions\n",
      "42 of 153 iterantions\n",
      "43 of 153 iterantions\n",
      "44 of 153 iterantions\n",
      "45 of 153 iterantions\n",
      "46 of 153 iterantions\n",
      "47 of 153 iterantions\n",
      "48 of 153 iterantions\n",
      "49 of 153 iterantions\n",
      "50 of 153 iterantions\n",
      "51 of 153 iterantions\n",
      "52 of 153 iterantions\n",
      "53 of 153 iterantions\n",
      "54 of 153 iterantions\n",
      "55 of 153 iterantions\n",
      "56 of 153 iterantions\n",
      "57 of 153 iterantions\n",
      "58 of 153 iterantions\n",
      "59 of 153 iterantions\n",
      "60 of 153 iterantions\n",
      "61 of 153 iterantions\n",
      "62 of 153 iterantions\n",
      "63 of 153 iterantions\n",
      "64 of 153 iterantions\n",
      "65 of 153 iterantions\n",
      "66 of 153 iterantions\n",
      "67 of 153 iterantions\n",
      "68 of 153 iterantions\n",
      "69 of 153 iterantions\n",
      "70 of 153 iterantions\n",
      "71 of 153 iterantions\n",
      "72 of 153 iterantions\n",
      "73 of 153 iterantions\n",
      "74 of 153 iterantions\n",
      "75 of 153 iterantions\n",
      "76 of 153 iterantions\n",
      "77 of 153 iterantions\n",
      "78 of 153 iterantions\n",
      "79 of 153 iterantions\n",
      "80 of 153 iterantions\n",
      "81 of 153 iterantions\n",
      "82 of 153 iterantions\n",
      "83 of 153 iterantions\n",
      "84 of 153 iterantions\n",
      "85 of 153 iterantions\n",
      "86 of 153 iterantions\n",
      "87 of 153 iterantions\n",
      "88 of 153 iterantions\n",
      "89 of 153 iterantions\n",
      "90 of 153 iterantions\n",
      "91 of 153 iterantions\n",
      "92 of 153 iterantions\n",
      "93 of 153 iterantions\n",
      "94 of 153 iterantions\n",
      "95 of 153 iterantions\n",
      "96 of 153 iterantions\n",
      "97 of 153 iterantions\n",
      "98 of 153 iterantions\n",
      "99 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 of 153 iterantions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/mt404vm51mvcpt_t2j5z7dbm0000gn/T/ipykernel_52628/276985217.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "tot = enc_ts.shape[0]\n",
    "dv_sim = []\n",
    "dv_sim_ = []\n",
    "df = pd.Series(np.array(eviden.index)).reset_index(name='id').drop(['index'], axis=1)\n",
    "for i in range(tot):\n",
    "    print(f'{i} of {tot} iterantions')\n",
    "    similarity = cos(torch.from_numpy(enc_ev), torch.from_numpy(enc_ts[i]))\n",
    "    df[df_test.index[i]] = similarity.detach().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/SBERT_2/ts_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ev = []\n",
    "for claim in df_test.index:\n",
    "    ds = df.set_index('id').loc[:, [claim]] \n",
    "    ds = ds[ds[claim] >= 0.995]\n",
    "    pr_ev.append(list(ds.index))\n",
    "df_test['evidences'] = pr_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in df_test.evidences if len(i) == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8660.086330935252"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(i) for i in df_test.evidences if len(i) != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_json('evidence_test_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
